{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ece5e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import h5py\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../stylegan3')\n",
    "\n",
    "from utils.L2FPipeline import L2FPipeline\n",
    "from stylegan_generator import StyleGANGenerator\n",
    "from models.MultilabelResnetClassifier import MultilabelResnetClassifier\n",
    "from models.LatentFeatureExtractor import LatentFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8003de0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 0.0863, -0.2087, -0.0529,  1.9157, -0.7995, -1.2684, -0.7082, -0.4558,\n",
      "        -0.4521,  0.9718,  0.8288,  0.5547, -0.8654, -0.0424, -1.6860, -0.4464,\n",
      "        -0.1741,  1.5128,  0.0182, -1.3632, -0.5289,  1.5866,  2.2250, -0.5918,\n",
      "         0.6909, -0.7142,  0.4625, -1.2063,  0.6286,  1.0684,  0.0952, -0.8414,\n",
      "        -0.0596,  0.2289,  0.2742, -0.4522,  2.3054,  1.0486, -1.0632,  1.8720,\n",
      "        -0.2277,  0.7040,  0.9490,  0.5992,  0.6675, -0.8961,  2.5029, -0.9136,\n",
      "         0.6681, -2.6288, -0.3084,  0.6764,  1.1316, -0.5700, -0.6827,  0.6213,\n",
      "        -1.0184,  0.0625,  0.3167,  0.5707, -0.6916, -2.1364,  2.3244,  1.0641,\n",
      "         0.2128, -0.0191,  0.2481, -1.8346, -0.1900, -1.5825, -0.5059,  2.1864,\n",
      "        -0.7260,  1.1937,  0.6262, -2.6140,  0.6539, -1.5208,  0.0103, -1.4978,\n",
      "        -0.5254, -2.6559, -1.9320,  1.3012,  0.1731, -1.4431, -2.0771,  0.3184,\n",
      "         0.6851, -1.2064,  0.1635,  0.6987,  0.4779, -0.8020,  1.0947, -0.2922,\n",
      "         1.3414, -1.4261, -1.7614, -0.4801,  0.8181,  2.0983,  1.6568,  0.2862,\n",
      "        -1.2465, -0.5948, -1.2790,  0.0095, -0.1949, -0.9083,  0.9689,  2.0674,\n",
      "        -0.2009,  1.8992,  0.6744,  0.8871,  0.9910, -3.7174,  1.5613,  2.3372,\n",
      "        -2.6083, -0.9066,  0.6743, -0.9357, -1.5971, -0.6363,  0.6191, -2.0210,\n",
      "        -0.2685, -0.2025,  0.3399,  0.6259, -1.1906,  1.4133, -0.9872, -2.0911,\n",
      "        -1.4332, -0.5793, -0.9280,  0.2391,  0.8287,  1.1352, -0.2077,  1.0550,\n",
      "         1.3384, -1.8687,  0.4132,  1.0181, -0.5957, -0.9947, -1.5940,  1.1103,\n",
      "        -0.1066,  0.3211, -1.3619, -0.4411,  1.8980,  0.5515, -1.4418, -1.7576,\n",
      "        -0.5759,  0.8725, -0.4244, -0.2975,  1.0748, -0.2722, -0.0445,  0.8255,\n",
      "        -0.5659, -0.9181, -1.5262,  0.7092, -0.5065,  0.1152, -0.4132,  0.6952,\n",
      "        -0.7596,  1.0682, -1.3251, -0.5022, -1.2115, -1.0475, -0.8153,  0.2842,\n",
      "         0.0630, -0.0102, -1.1683,  0.5025,  0.3789, -0.5724, -0.7762,  1.3282,\n",
      "         0.5745, -0.3165,  1.0359,  0.6576,  1.2300,  0.0820,  0.9630, -0.2543,\n",
      "         0.1998,  0.0559, -1.0504, -0.3473, -0.2979, -0.0099,  1.2920,  0.2273,\n",
      "        -1.0782,  0.4022, -0.5755,  1.2153,  0.1518, -1.6809,  0.4843, -0.8744,\n",
      "         0.8479,  0.9132,  0.9834,  0.4902, -0.3028,  0.7242, -0.1618,  0.3254,\n",
      "        -1.2974, -0.2877, -0.2030, -0.6276, -0.8891, -1.0300,  1.2936,  1.3228,\n",
      "         1.1182, -1.0438,  0.1350,  0.2560, -0.9065,  0.0649, -1.2307, -0.0675,\n",
      "         1.1899, -1.7485, -1.7034,  0.0917,  1.1809, -0.7851, -1.2016, -1.0147,\n",
      "         0.4993, -1.0122,  0.7907, -0.4929, -0.7036,  0.4810, -0.3587,  0.6368,\n",
      "        -0.6079,  0.3930,  1.6364, -0.4303, -1.0940, -1.3262, -0.7285, -0.8763,\n",
      "         0.1687, -0.5396, -0.9725,  0.0732,  0.5291,  0.6150, -1.4075, -0.7921,\n",
      "        -0.1546,  0.2805, -0.7120, -1.2572, -0.6247, -0.8415, -1.6328, -0.8275,\n",
      "         0.4598,  1.0070, -0.0062,  0.1777,  1.9855, -0.9624, -1.4757, -1.2330,\n",
      "         1.8053, -0.1459,  0.6484, -0.3299,  0.7200, -1.2244,  2.8846, -1.0805,\n",
      "        -1.2430, -1.1357, -0.8246, -0.3070, -1.9385, -0.4736,  1.4600, -0.7203,\n",
      "        -0.5346,  1.2772, -0.9384, -1.1239,  0.4000, -0.1700, -0.5931, -0.1467,\n",
      "         0.4896,  0.0234,  0.1788, -0.0836,  0.6643, -0.4748,  1.3156,  1.3945,\n",
      "         0.1414, -0.9139, -1.6199, -1.9396,  1.0520,  0.3961, -0.5833, -0.0614,\n",
      "         1.0423, -0.0712, -0.2238,  0.2442, -2.6900, -0.0478,  1.4121,  0.1376,\n",
      "         0.5354, -1.5418,  0.0402, -0.9273, -1.0607, -0.4491, -0.1149, -0.5334,\n",
      "        -0.4185, -1.0742,  1.3410,  0.0479,  0.5848,  0.4641, -1.2610,  0.2859,\n",
      "        -0.6870,  0.1601,  0.4140,  1.0545, -0.6067,  0.0632,  1.2966, -0.4825,\n",
      "         0.2156,  0.6081,  1.0236, -0.0271,  0.2104, -0.7689, -1.6180,  0.7928,\n",
      "         0.9540, -0.4861, -0.8943, -0.8093, -0.6860, -1.2860,  1.9301,  0.8262,\n",
      "        -0.5558, -2.4292, -1.1705,  0.7073, -1.5544, -0.8670, -2.3276,  0.0369,\n",
      "         0.2955, -0.2545, -0.1318,  1.4395, -1.2324, -2.4096, -1.8183,  0.7699,\n",
      "        -0.1351,  0.5098, -1.9258,  0.0962,  2.0894, -0.8825,  1.1228, -1.3234,\n",
      "        -0.7200, -0.5835,  1.1734, -1.3713,  0.0921, -0.1780,  1.0366, -0.5927,\n",
      "         0.0042,  1.5292,  0.1742,  0.0095,  1.0116, -0.4566, -0.7108, -0.4076,\n",
      "         0.5279, -0.0760, -1.2676,  0.4340,  0.0340,  0.4196,  1.0334,  0.6839,\n",
      "         0.2564, -0.2940,  0.2208,  0.8765,  0.3202, -0.7519,  0.1830,  0.3963,\n",
      "         0.7787,  0.3541,  1.0890, -1.0566, -1.4972, -0.2636, -0.9800,  1.4453,\n",
      "         0.5329, -0.9294, -0.1753, -0.0413, -0.6848, -1.6695, -0.2554, -0.9123,\n",
      "         1.3717,  0.3938, -1.0422,  0.7562, -0.3428,  0.2419, -0.0919,  0.6619,\n",
      "        -0.0975,  0.1248, -0.2258, -0.1015, -0.5946,  0.8260, -1.1480, -0.4336,\n",
      "        -0.4123, -0.0965, -1.9505,  0.6569,  0.7503, -0.0921, -0.5179, -0.7132,\n",
      "         0.5109,  1.6920, -0.1322, -1.7413, -1.4718,  0.8811, -0.4945, -1.1423,\n",
      "        -0.6763,  1.3490, -0.4553, -0.2027, -0.8357, -2.9051, -0.1624, -0.6208,\n",
      "        -0.3668, -1.3542,  1.2475,  0.6446, -0.3993, -0.0261,  0.6519, -0.6109,\n",
      "        -0.5876, -0.5917, -1.4623, -2.0579, -0.4898, -0.8751, -1.0213, -0.2823,\n",
      "         0.6492,  0.6091, -0.2399, -1.1381, -0.0164,  0.9727, -2.3203, -0.7979]), tensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.]))\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "data_path = '/home/robert/data/diploma-thesis/datasets/stylegan3/tpsi_1/latents/sample_z.h5'\n",
    "n_classes = 10\n",
    "\n",
    "data = None\n",
    "with h5py.File(data_path, 'r') as f:\n",
    "    data = f['z'][:]\n",
    "\n",
    "dataset = TensorDataset(torch.Tensor(data),torch.randint(0,2,(len(data), n_classes)).to(torch.float32))\n",
    "train_data, valid_data, test_data = random_split(dataset, [0.8, 0.1, 0.1])\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dc5edb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256000, 512)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47f453f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_pkl = 'https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-256x256.pkl'\n",
    "classifier_weights = '/home/robert/data/diploma-thesis/weights/classfier/resnet34_celeba10attr_10e.pt'\n",
    "\n",
    "generator = StyleGANGenerator(network_pkl)\n",
    "classifier = MultilabelResnetClassifier(n_classes=10)\n",
    "classifier.load_state_dict(torch.load(classifier_weights))\n",
    "\n",
    "pipeline = L2FPipeline(generator = generator, classifier = classifier, tpsi=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e198d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-4\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = LatentFeatureExtractor(n_classes=n_classes).cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate)\n",
    "\n",
    "save_filename = 'latent_feature_extractor_a.pt'\n",
    "\n",
    "loss = {}\n",
    "\n",
    "loss['train'] = []\n",
    "loss['valid'] = []\n",
    "loss['test'] = []\n",
    "best_valid_loss = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bed9e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  1.0000,  0.0000,  ..., -0.8616,  0.8153,  0.5804],\n",
      "        [ 1.0000,  0.0000,  1.0000,  ..., -0.0961, -0.3703, -2.9571],\n",
      "        [ 1.0000,  0.0000,  1.0000,  ...,  0.6860, -1.0162,  1.2216],\n",
      "        ...,\n",
      "        [ 0.0000,  1.0000,  1.0000,  ...,  0.8670,  1.6287, -0.3835],\n",
      "        [ 1.0000,  0.0000,  1.0000,  ...,  0.8515,  0.4823,  0.2658],\n",
      "        [ 0.0000,  1.0000,  0.0000,  ..., -0.1803, -1.9265, -0.4810]],\n",
      "       device='cuda:0')\n",
      "tensor([[1.4137e-01, 4.8823e-11, 1.0000e+00, 4.0576e-10, 6.3939e-08, 1.4851e-10,\n",
      "         2.0065e-11, 1.0000e+00, 1.9333e-04, 8.2050e-16],\n",
      "        [9.9927e-01, 9.9580e-01, 9.9961e-01, 1.4365e-05, 4.8892e-06, 5.9774e-01,\n",
      "         7.7415e-07, 1.0000e+00, 4.1330e-06, 4.6605e-07],\n",
      "        [2.8195e-03, 9.9999e-01, 9.9992e-01, 3.4302e-02, 2.8263e-05, 7.4685e-10,\n",
      "         3.0275e-05, 9.9937e-01, 1.0000e+00, 2.8163e-06],\n",
      "        [1.4588e-05, 3.2742e-07, 9.6592e-01, 1.0000e+00, 3.9051e-01, 3.5996e-10,\n",
      "         2.3442e-07, 4.2818e-03, 1.1128e-02, 3.3709e-06],\n",
      "        [5.7911e-03, 8.6384e-01, 9.9255e-01, 1.3162e-04, 2.6887e-07, 3.4482e-03,\n",
      "         1.6256e-03, 7.2054e-01, 3.9837e-01, 8.0534e-07],\n",
      "        [9.9932e-01, 4.3392e-10, 9.9998e-01, 2.0033e-08, 1.7348e-06, 1.7560e-01,\n",
      "         8.1895e-09, 9.9996e-01, 9.3484e-01, 3.7660e-10],\n",
      "        [9.9900e-01, 2.7845e-09, 1.0000e+00, 1.5448e-07, 7.9894e-04, 2.3718e-07,\n",
      "         1.2126e-08, 1.0000e+00, 2.4202e-08, 4.0514e-12],\n",
      "        [7.3753e-05, 4.5693e-02, 9.9977e-01, 1.5654e-07, 1.0003e-04, 1.9806e-04,\n",
      "         2.2388e-07, 9.8336e-01, 3.9045e-07, 4.2126e-08],\n",
      "        [7.8845e-01, 5.7561e-02, 2.1956e-01, 1.0000e+00, 3.8677e-04, 1.8983e-04,\n",
      "         4.2264e-08, 1.1857e-01, 1.0000e+00, 1.2295e-04],\n",
      "        [4.5723e-04, 9.8402e-01, 9.9814e-01, 6.9076e-01, 1.1191e-04, 7.8044e-07,\n",
      "         4.9240e-04, 2.6747e-02, 1.7607e-01, 7.3748e-05],\n",
      "        [5.3400e-02, 8.4239e-07, 1.0000e+00, 7.9211e-15, 2.7407e-03, 9.9947e-01,\n",
      "         2.8598e-13, 4.0920e-01, 9.9999e-01, 1.5925e-10],\n",
      "        [9.4966e-01, 2.2821e-08, 9.9997e-01, 6.3274e-02, 1.5328e-04, 1.5629e-02,\n",
      "         4.3436e-07, 1.0000e+00, 9.1915e-03, 3.3633e-09],\n",
      "        [2.2311e-01, 6.6139e-03, 9.9910e-01, 1.8038e-04, 2.2808e-07, 1.1076e-01,\n",
      "         2.0426e-06, 9.9999e-01, 1.7597e-06, 1.7583e-08],\n",
      "        [1.0000e+00, 2.7448e-11, 9.9998e-01, 4.4843e-04, 6.8066e-05, 9.4463e-03,\n",
      "         9.0346e-10, 1.0000e+00, 9.5270e-01, 1.1504e-09],\n",
      "        [9.6929e-01, 7.8042e-10, 1.0000e+00, 2.5654e-19, 3.3762e-08, 1.1497e-06,\n",
      "         6.0268e-21, 1.0000e+00, 1.1915e-04, 6.6750e-18],\n",
      "        [3.6856e-02, 8.1263e-10, 1.0000e+00, 9.9544e-08, 2.2868e-02, 1.8440e-08,\n",
      "         1.5858e-10, 1.0000e+00, 7.0336e-01, 7.5648e-09],\n",
      "        [1.9030e-04, 7.3614e-01, 9.9857e-01, 9.9995e-01, 4.5689e-05, 4.8828e-08,\n",
      "         7.7173e-04, 2.3919e-04, 1.0498e-07, 3.6503e-04],\n",
      "        [9.9999e-01, 2.6431e-12, 1.0000e+00, 2.6885e-05, 8.6690e-01, 2.0472e-06,\n",
      "         2.4372e-10, 1.0000e+00, 2.7800e-02, 4.1137e-10],\n",
      "        [9.6328e-01, 8.9172e-06, 9.9995e-01, 5.4524e-03, 9.7862e-01, 2.7049e-06,\n",
      "         1.0006e-05, 2.5461e-01, 3.8672e-03, 6.7923e-08],\n",
      "        [8.0949e-01, 2.2933e-08, 1.0000e+00, 7.1851e-06, 7.0566e-02, 2.2809e-05,\n",
      "         6.7226e-08, 9.9955e-01, 2.4691e-02, 1.0169e-06],\n",
      "        [9.9645e-01, 2.2886e-06, 1.0000e+00, 9.9510e-01, 9.1459e-01, 2.5286e-04,\n",
      "         7.9115e-08, 2.5993e-01, 2.3275e-04, 7.4230e-07],\n",
      "        [1.0232e-01, 2.6082e-04, 9.5077e-01, 5.9820e-04, 5.2267e-04, 7.1141e-02,\n",
      "         6.8256e-05, 9.9957e-01, 3.1180e-04, 1.4609e-06],\n",
      "        [5.2316e-01, 3.7104e-09, 1.0000e+00, 8.4456e-09, 3.5815e-04, 1.5110e-06,\n",
      "         2.7397e-09, 9.9967e-01, 1.0000e+00, 5.0039e-08],\n",
      "        [9.9963e-01, 1.1565e-10, 1.0000e+00, 2.8391e-15, 4.7553e-05, 7.0564e-05,\n",
      "         2.3007e-16, 1.0000e+00, 2.4815e-03, 7.0490e-16],\n",
      "        [9.3760e-02, 1.6458e-05, 9.2448e-01, 9.9998e-01, 4.1182e-06, 6.0654e-07,\n",
      "         9.6506e-05, 9.4072e-02, 5.8659e-04, 2.5206e-07],\n",
      "        [9.0621e-01, 6.2945e-15, 1.0000e+00, 8.3531e-13, 2.3846e-06, 3.6421e-07,\n",
      "         2.2224e-12, 1.0000e+00, 5.1742e-01, 1.5631e-13],\n",
      "        [1.7629e-01, 4.2092e-08, 9.9999e-01, 6.9130e-04, 1.6035e-07, 1.0733e-09,\n",
      "         1.0365e-11, 9.9587e-01, 9.9999e-01, 4.2177e-08],\n",
      "        [3.4456e-01, 1.1885e-01, 3.1435e-01, 9.2152e-01, 1.0909e-01, 8.4980e-07,\n",
      "         3.3423e-04, 9.9335e-01, 7.6023e-01, 1.9931e-05],\n",
      "        [6.9166e-05, 9.8881e-01, 8.7476e-01, 1.0000e+00, 1.4264e-04, 3.0978e-06,\n",
      "         7.0469e-05, 8.1127e-03, 8.2833e-02, 3.5413e-06],\n",
      "        [9.9998e-01, 1.9377e-12, 1.0000e+00, 4.7477e-11, 1.1973e-09, 6.8712e-07,\n",
      "         3.9303e-14, 1.0000e+00, 9.9985e-01, 6.9010e-14],\n",
      "        [6.5902e-04, 9.9846e-01, 9.7798e-01, 2.8914e-01, 2.7957e-01, 1.2933e-04,\n",
      "         1.0756e-02, 9.1620e-01, 2.1420e-03, 2.4849e-06],\n",
      "        [9.8880e-02, 6.8048e-07, 6.8210e-02, 9.7922e-01, 9.9845e-01, 1.9700e-09,\n",
      "         1.2315e-02, 8.1694e-01, 6.0519e-03, 8.4157e-06],\n",
      "        [1.2500e-01, 1.7029e-06, 9.9751e-01, 1.2048e-02, 2.0264e-06, 7.2820e-08,\n",
      "         2.8243e-07, 9.8371e-01, 1.1994e-03, 3.5563e-11],\n",
      "        [9.9978e-01, 1.4295e-12, 1.0000e+00, 6.5765e-11, 5.4748e-04, 4.7285e-02,\n",
      "         5.2266e-20, 1.0000e+00, 1.0000e+00, 1.9544e-13],\n",
      "        [8.2579e-01, 5.6580e-01, 9.9821e-01, 1.0000e+00, 2.4311e-04, 1.3110e-07,\n",
      "         1.4683e-09, 4.3814e-04, 1.0000e+00, 2.9948e-04],\n",
      "        [8.1653e-04, 7.0664e-10, 9.9999e-01, 2.0346e-01, 3.9379e-02, 7.5880e-16,\n",
      "         1.1066e-08, 9.6403e-01, 2.0270e-04, 8.2334e-09],\n",
      "        [5.8527e-06, 9.8665e-01, 2.6264e-01, 2.3410e-03, 2.1212e-09, 5.2538e-03,\n",
      "         5.4970e-05, 9.9963e-01, 9.9999e-01, 2.3481e-08],\n",
      "        [1.7472e-03, 1.4462e-08, 9.9985e-01, 9.5841e-01, 2.3002e-04, 4.2962e-05,\n",
      "         9.9895e-09, 9.9998e-01, 9.9990e-01, 8.2910e-10],\n",
      "        [9.9978e-01, 3.2183e-08, 1.0000e+00, 1.1325e-07, 6.6865e-07, 4.9214e-01,\n",
      "         1.4517e-10, 9.9910e-01, 1.0000e+00, 1.0135e-09],\n",
      "        [1.0000e+00, 5.7372e-12, 1.0000e+00, 9.4478e-06, 1.1723e-04, 1.1884e-05,\n",
      "         1.7541e-09, 1.0000e+00, 9.9897e-01, 3.6474e-12],\n",
      "        [4.4445e-01, 1.1693e-05, 1.0000e+00, 1.2393e-02, 6.5268e-04, 4.5988e-04,\n",
      "         1.3556e-10, 4.8671e-03, 9.9978e-01, 1.5356e-03],\n",
      "        [7.8133e-01, 9.1282e-09, 1.0000e+00, 2.5479e-07, 1.6209e-04, 4.1227e-04,\n",
      "         1.6464e-10, 1.0000e+00, 6.1658e-04, 2.9463e-11],\n",
      "        [2.1496e-03, 2.2440e-08, 9.9999e-01, 3.7096e-06, 8.4678e-08, 4.4547e-07,\n",
      "         9.0872e-08, 9.8607e-01, 5.4194e-02, 2.6928e-13],\n",
      "        [5.1597e-02, 1.0000e+00, 9.6363e-01, 1.0000e+00, 4.9796e-03, 2.2310e-07,\n",
      "         1.6079e-06, 9.9967e-01, 7.0872e-01, 2.3424e-09],\n",
      "        [9.8982e-01, 2.8479e-06, 9.7656e-01, 9.8834e-01, 8.2328e-01, 2.2318e-05,\n",
      "         1.3365e-03, 8.5001e-01, 4.9952e-01, 1.7029e-04],\n",
      "        [1.4946e-01, 9.9974e-01, 1.0000e+00, 4.5033e-02, 7.6845e-06, 4.1914e-04,\n",
      "         2.5845e-09, 1.0000e+00, 1.8833e-01, 6.5596e-07],\n",
      "        [1.4317e-01, 1.6777e-04, 9.9999e-01, 1.0000e+00, 1.3339e-05, 7.0118e-05,\n",
      "         6.3990e-08, 5.1931e-04, 9.9768e-01, 9.1116e-06],\n",
      "        [3.6788e-09, 4.2215e-04, 4.8726e-01, 1.0000e+00, 1.5977e-06, 2.4079e-05,\n",
      "         2.2745e-08, 2.3582e-02, 1.0579e-09, 1.6228e-08],\n",
      "        [2.0840e-01, 4.0076e-03, 1.0000e+00, 6.5916e-07, 9.9998e-01, 2.1468e-12,\n",
      "         4.3960e-04, 9.9181e-01, 9.9526e-01, 3.0108e-08],\n",
      "        [1.5292e-01, 1.7170e-06, 9.9952e-01, 9.9890e-01, 3.2723e-04, 9.1972e-08,\n",
      "         2.6021e-05, 7.4724e-04, 9.9935e-01, 1.8388e-04],\n",
      "        [2.1725e-01, 9.9974e-01, 9.9996e-01, 9.9547e-01, 9.6649e-05, 1.4068e-06,\n",
      "         7.7314e-09, 8.1885e-01, 9.9256e-01, 4.6459e-03],\n",
      "        [9.6683e-01, 2.1681e-01, 9.9979e-01, 9.9590e-01, 8.8194e-01, 4.0877e-06,\n",
      "         6.6738e-07, 9.9987e-01, 9.9999e-01, 8.6692e-07],\n",
      "        [2.1640e-02, 6.2003e-06, 9.8106e-01, 9.9938e-01, 1.2928e-05, 7.7706e-06,\n",
      "         2.7261e-03, 2.3225e-02, 9.6261e-01, 1.1533e-08],\n",
      "        [3.4244e-04, 1.9140e-04, 3.6241e-01, 9.8658e-01, 6.9903e-03, 4.3928e-03,\n",
      "         1.4452e-03, 3.8915e-02, 1.0000e+00, 6.2153e-05],\n",
      "        [3.0992e-05, 9.8339e-01, 9.9991e-01, 9.9985e-01, 1.4938e-05, 2.6430e-02,\n",
      "         4.9246e-04, 1.0000e+00, 2.1809e-03, 3.7907e-05],\n",
      "        [9.6352e-01, 1.9230e-01, 1.0000e+00, 9.2444e-01, 5.2728e-02, 9.8366e-05,\n",
      "         4.1510e-05, 9.1380e-01, 3.4281e-08, 1.7416e-05],\n",
      "        [7.3951e-02, 9.7295e-03, 9.9991e-01, 3.3971e-02, 3.1882e-01, 5.4969e-10,\n",
      "         2.3014e-07, 1.0000e+00, 5.2131e-08, 2.8148e-10],\n",
      "        [4.6845e-02, 5.6327e-03, 5.6696e-01, 1.0000e+00, 1.2608e-02, 8.7342e-07,\n",
      "         4.1923e-06, 9.9467e-01, 3.1443e-05, 5.2183e-06],\n",
      "        [2.3432e-01, 9.9998e-01, 1.5143e-01, 9.9630e-01, 1.6812e-03, 2.1840e-08,\n",
      "         3.2326e-01, 6.9581e-01, 1.8678e-04, 1.6310e-05],\n",
      "        [5.9356e-02, 5.3813e-09, 1.0000e+00, 2.1378e-08, 2.4399e-07, 9.9993e-01,\n",
      "         5.6344e-11, 9.9958e-01, 1.4835e-08, 1.1373e-12],\n",
      "        [9.9930e-01, 2.3017e-14, 1.0000e+00, 2.0545e-10, 1.3988e-01, 1.1429e-12,\n",
      "         3.2529e-15, 1.0000e+00, 1.9402e-07, 1.1800e-15],\n",
      "        [9.9998e-01, 7.3192e-12, 9.9922e-01, 1.0847e-05, 2.2013e-05, 3.0181e-01,\n",
      "         2.9865e-07, 9.9999e-01, 9.9991e-01, 6.6722e-09],\n",
      "        [3.3274e-03, 1.7121e-08, 9.9950e-01, 9.9999e-01, 3.8310e-09, 8.2971e-10,\n",
      "         3.1358e-06, 4.6309e-01, 1.0000e+00, 7.4128e-09],\n",
      "        [2.4579e-07, 3.7524e-08, 9.9937e-01, 9.9982e-01, 1.1412e-03, 6.8598e-08,\n",
      "         6.3430e-09, 5.4275e-01, 1.9192e-03, 1.4153e-09]])\n",
      "tensor([[1.4137e-01, 4.8823e-11, 1.0000e+00, 4.0576e-10, 6.3939e-08, 1.4851e-10,\n",
      "         2.0065e-11, 1.0000e+00, 1.9333e-04, 8.2050e-16],\n",
      "        [9.9927e-01, 9.9580e-01, 9.9961e-01, 1.4365e-05, 4.8892e-06, 5.9774e-01,\n",
      "         7.7415e-07, 1.0000e+00, 4.1330e-06, 4.6605e-07],\n",
      "        [2.8195e-03, 9.9999e-01, 9.9992e-01, 3.4302e-02, 2.8263e-05, 7.4685e-10,\n",
      "         3.0275e-05, 9.9937e-01, 1.0000e+00, 2.8163e-06],\n",
      "        [1.4588e-05, 3.2742e-07, 9.6592e-01, 1.0000e+00, 3.9051e-01, 3.5996e-10,\n",
      "         2.3442e-07, 4.2818e-03, 1.1128e-02, 3.3709e-06],\n",
      "        [5.7911e-03, 8.6384e-01, 9.9255e-01, 1.3162e-04, 2.6887e-07, 3.4482e-03,\n",
      "         1.6256e-03, 7.2054e-01, 3.9837e-01, 8.0534e-07],\n",
      "        [9.9932e-01, 4.3392e-10, 9.9998e-01, 2.0033e-08, 1.7348e-06, 1.7560e-01,\n",
      "         8.1895e-09, 9.9996e-01, 9.3484e-01, 3.7660e-10],\n",
      "        [9.9900e-01, 2.7845e-09, 1.0000e+00, 1.5448e-07, 7.9894e-04, 2.3718e-07,\n",
      "         1.2126e-08, 1.0000e+00, 2.4202e-08, 4.0514e-12],\n",
      "        [7.3753e-05, 4.5693e-02, 9.9977e-01, 1.5654e-07, 1.0003e-04, 1.9806e-04,\n",
      "         2.2388e-07, 9.8336e-01, 3.9045e-07, 4.2126e-08],\n",
      "        [7.8845e-01, 5.7561e-02, 2.1956e-01, 1.0000e+00, 3.8677e-04, 1.8983e-04,\n",
      "         4.2264e-08, 1.1857e-01, 1.0000e+00, 1.2295e-04],\n",
      "        [4.5723e-04, 9.8402e-01, 9.9814e-01, 6.9076e-01, 1.1191e-04, 7.8044e-07,\n",
      "         4.9240e-04, 2.6747e-02, 1.7607e-01, 7.3748e-05],\n",
      "        [5.3400e-02, 8.4239e-07, 1.0000e+00, 7.9211e-15, 2.7407e-03, 9.9947e-01,\n",
      "         2.8598e-13, 4.0920e-01, 9.9999e-01, 1.5925e-10],\n",
      "        [9.4966e-01, 2.2821e-08, 9.9997e-01, 6.3274e-02, 1.5328e-04, 1.5629e-02,\n",
      "         4.3436e-07, 1.0000e+00, 9.1915e-03, 3.3633e-09],\n",
      "        [2.2311e-01, 6.6139e-03, 9.9910e-01, 1.8038e-04, 2.2808e-07, 1.1076e-01,\n",
      "         2.0426e-06, 9.9999e-01, 1.7597e-06, 1.7583e-08],\n",
      "        [1.0000e+00, 2.7448e-11, 9.9998e-01, 4.4843e-04, 6.8066e-05, 9.4463e-03,\n",
      "         9.0346e-10, 1.0000e+00, 9.5270e-01, 1.1504e-09],\n",
      "        [9.6929e-01, 7.8042e-10, 1.0000e+00, 2.5654e-19, 3.3762e-08, 1.1497e-06,\n",
      "         6.0268e-21, 1.0000e+00, 1.1915e-04, 6.6750e-18],\n",
      "        [3.6856e-02, 8.1263e-10, 1.0000e+00, 9.9544e-08, 2.2868e-02, 1.8440e-08,\n",
      "         1.5858e-10, 1.0000e+00, 7.0336e-01, 7.5648e-09],\n",
      "        [1.9030e-04, 7.3614e-01, 9.9857e-01, 9.9995e-01, 4.5689e-05, 4.8828e-08,\n",
      "         7.7173e-04, 2.3919e-04, 1.0498e-07, 3.6503e-04],\n",
      "        [9.9999e-01, 2.6431e-12, 1.0000e+00, 2.6885e-05, 8.6690e-01, 2.0472e-06,\n",
      "         2.4372e-10, 1.0000e+00, 2.7800e-02, 4.1137e-10],\n",
      "        [9.6328e-01, 8.9172e-06, 9.9995e-01, 5.4524e-03, 9.7862e-01, 2.7049e-06,\n",
      "         1.0006e-05, 2.5461e-01, 3.8672e-03, 6.7923e-08],\n",
      "        [8.0949e-01, 2.2933e-08, 1.0000e+00, 7.1851e-06, 7.0566e-02, 2.2809e-05,\n",
      "         6.7226e-08, 9.9955e-01, 2.4691e-02, 1.0169e-06],\n",
      "        [9.9645e-01, 2.2886e-06, 1.0000e+00, 9.9510e-01, 9.1459e-01, 2.5286e-04,\n",
      "         7.9115e-08, 2.5993e-01, 2.3275e-04, 7.4230e-07],\n",
      "        [1.0232e-01, 2.6082e-04, 9.5077e-01, 5.9820e-04, 5.2267e-04, 7.1141e-02,\n",
      "         6.8256e-05, 9.9957e-01, 3.1180e-04, 1.4609e-06],\n",
      "        [5.2316e-01, 3.7104e-09, 1.0000e+00, 8.4456e-09, 3.5815e-04, 1.5110e-06,\n",
      "         2.7397e-09, 9.9967e-01, 1.0000e+00, 5.0039e-08],\n",
      "        [9.9963e-01, 1.1565e-10, 1.0000e+00, 2.8391e-15, 4.7553e-05, 7.0564e-05,\n",
      "         2.3007e-16, 1.0000e+00, 2.4815e-03, 7.0490e-16],\n",
      "        [9.3760e-02, 1.6458e-05, 9.2448e-01, 9.9998e-01, 4.1182e-06, 6.0654e-07,\n",
      "         9.6506e-05, 9.4072e-02, 5.8659e-04, 2.5206e-07],\n",
      "        [9.0621e-01, 6.2945e-15, 1.0000e+00, 8.3531e-13, 2.3846e-06, 3.6421e-07,\n",
      "         2.2224e-12, 1.0000e+00, 5.1742e-01, 1.5631e-13],\n",
      "        [1.7629e-01, 4.2092e-08, 9.9999e-01, 6.9130e-04, 1.6035e-07, 1.0733e-09,\n",
      "         1.0365e-11, 9.9587e-01, 9.9999e-01, 4.2177e-08],\n",
      "        [3.4456e-01, 1.1885e-01, 3.1435e-01, 9.2152e-01, 1.0909e-01, 8.4980e-07,\n",
      "         3.3423e-04, 9.9335e-01, 7.6023e-01, 1.9931e-05],\n",
      "        [6.9166e-05, 9.8881e-01, 8.7476e-01, 1.0000e+00, 1.4264e-04, 3.0978e-06,\n",
      "         7.0469e-05, 8.1127e-03, 8.2833e-02, 3.5413e-06],\n",
      "        [9.9998e-01, 1.9377e-12, 1.0000e+00, 4.7477e-11, 1.1973e-09, 6.8712e-07,\n",
      "         3.9303e-14, 1.0000e+00, 9.9985e-01, 6.9010e-14],\n",
      "        [6.5902e-04, 9.9846e-01, 9.7798e-01, 2.8914e-01, 2.7957e-01, 1.2933e-04,\n",
      "         1.0756e-02, 9.1620e-01, 2.1420e-03, 2.4849e-06],\n",
      "        [9.8880e-02, 6.8048e-07, 6.8210e-02, 9.7922e-01, 9.9845e-01, 1.9700e-09,\n",
      "         1.2315e-02, 8.1694e-01, 6.0519e-03, 8.4157e-06],\n",
      "        [1.2500e-01, 1.7029e-06, 9.9751e-01, 1.2048e-02, 2.0264e-06, 7.2820e-08,\n",
      "         2.8243e-07, 9.8371e-01, 1.1994e-03, 3.5563e-11],\n",
      "        [9.9978e-01, 1.4295e-12, 1.0000e+00, 6.5765e-11, 5.4748e-04, 4.7285e-02,\n",
      "         5.2266e-20, 1.0000e+00, 1.0000e+00, 1.9544e-13],\n",
      "        [8.2579e-01, 5.6580e-01, 9.9821e-01, 1.0000e+00, 2.4311e-04, 1.3110e-07,\n",
      "         1.4683e-09, 4.3814e-04, 1.0000e+00, 2.9948e-04],\n",
      "        [8.1653e-04, 7.0664e-10, 9.9999e-01, 2.0346e-01, 3.9379e-02, 7.5880e-16,\n",
      "         1.1066e-08, 9.6403e-01, 2.0270e-04, 8.2334e-09],\n",
      "        [5.8527e-06, 9.8665e-01, 2.6264e-01, 2.3410e-03, 2.1212e-09, 5.2538e-03,\n",
      "         5.4970e-05, 9.9963e-01, 9.9999e-01, 2.3481e-08],\n",
      "        [1.7472e-03, 1.4462e-08, 9.9985e-01, 9.5841e-01, 2.3002e-04, 4.2962e-05,\n",
      "         9.9895e-09, 9.9998e-01, 9.9990e-01, 8.2910e-10],\n",
      "        [9.9978e-01, 3.2183e-08, 1.0000e+00, 1.1325e-07, 6.6865e-07, 4.9214e-01,\n",
      "         1.4517e-10, 9.9910e-01, 1.0000e+00, 1.0135e-09],\n",
      "        [1.0000e+00, 5.7372e-12, 1.0000e+00, 9.4478e-06, 1.1723e-04, 1.1884e-05,\n",
      "         1.7541e-09, 1.0000e+00, 9.9897e-01, 3.6474e-12],\n",
      "        [4.4445e-01, 1.1693e-05, 1.0000e+00, 1.2393e-02, 6.5268e-04, 4.5988e-04,\n",
      "         1.3556e-10, 4.8671e-03, 9.9978e-01, 1.5356e-03],\n",
      "        [7.8133e-01, 9.1282e-09, 1.0000e+00, 2.5479e-07, 1.6209e-04, 4.1227e-04,\n",
      "         1.6464e-10, 1.0000e+00, 6.1658e-04, 2.9463e-11],\n",
      "        [2.1496e-03, 2.2440e-08, 9.9999e-01, 3.7096e-06, 8.4678e-08, 4.4547e-07,\n",
      "         9.0872e-08, 9.8607e-01, 5.4194e-02, 2.6928e-13],\n",
      "        [5.1597e-02, 1.0000e+00, 9.6363e-01, 1.0000e+00, 4.9796e-03, 2.2310e-07,\n",
      "         1.6079e-06, 9.9967e-01, 7.0872e-01, 2.3424e-09],\n",
      "        [9.8982e-01, 2.8479e-06, 9.7656e-01, 9.8834e-01, 8.2328e-01, 2.2318e-05,\n",
      "         1.3365e-03, 8.5001e-01, 4.9952e-01, 1.7029e-04],\n",
      "        [1.4946e-01, 9.9974e-01, 1.0000e+00, 4.5033e-02, 7.6845e-06, 4.1914e-04,\n",
      "         2.5845e-09, 1.0000e+00, 1.8833e-01, 6.5596e-07],\n",
      "        [1.4317e-01, 1.6777e-04, 9.9999e-01, 1.0000e+00, 1.3339e-05, 7.0118e-05,\n",
      "         6.3990e-08, 5.1931e-04, 9.9768e-01, 9.1116e-06],\n",
      "        [3.6788e-09, 4.2215e-04, 4.8726e-01, 1.0000e+00, 1.5977e-06, 2.4079e-05,\n",
      "         2.2745e-08, 2.3582e-02, 1.0579e-09, 1.6228e-08],\n",
      "        [2.0840e-01, 4.0076e-03, 1.0000e+00, 6.5916e-07, 9.9998e-01, 2.1468e-12,\n",
      "         4.3960e-04, 9.9181e-01, 9.9526e-01, 3.0108e-08],\n",
      "        [1.5292e-01, 1.7170e-06, 9.9952e-01, 9.9890e-01, 3.2723e-04, 9.1972e-08,\n",
      "         2.6021e-05, 7.4724e-04, 9.9935e-01, 1.8388e-04],\n",
      "        [2.1725e-01, 9.9974e-01, 9.9996e-01, 9.9547e-01, 9.6649e-05, 1.4068e-06,\n",
      "         7.7314e-09, 8.1885e-01, 9.9256e-01, 4.6459e-03],\n",
      "        [9.6683e-01, 2.1681e-01, 9.9979e-01, 9.9590e-01, 8.8194e-01, 4.0877e-06,\n",
      "         6.6738e-07, 9.9987e-01, 9.9999e-01, 8.6692e-07],\n",
      "        [2.1640e-02, 6.2003e-06, 9.8106e-01, 9.9938e-01, 1.2928e-05, 7.7706e-06,\n",
      "         2.7261e-03, 2.3225e-02, 9.6261e-01, 1.1533e-08],\n",
      "        [3.4244e-04, 1.9140e-04, 3.6241e-01, 9.8658e-01, 6.9903e-03, 4.3928e-03,\n",
      "         1.4452e-03, 3.8915e-02, 1.0000e+00, 6.2153e-05],\n",
      "        [3.0992e-05, 9.8339e-01, 9.9991e-01, 9.9985e-01, 1.4938e-05, 2.6430e-02,\n",
      "         4.9246e-04, 1.0000e+00, 2.1809e-03, 3.7907e-05],\n",
      "        [9.6352e-01, 1.9230e-01, 1.0000e+00, 9.2444e-01, 5.2728e-02, 9.8366e-05,\n",
      "         4.1510e-05, 9.1380e-01, 3.4281e-08, 1.7416e-05],\n",
      "        [7.3951e-02, 9.7295e-03, 9.9991e-01, 3.3971e-02, 3.1882e-01, 5.4969e-10,\n",
      "         2.3014e-07, 1.0000e+00, 5.2131e-08, 2.8148e-10],\n",
      "        [4.6845e-02, 5.6327e-03, 5.6696e-01, 1.0000e+00, 1.2608e-02, 8.7342e-07,\n",
      "         4.1923e-06, 9.9467e-01, 3.1443e-05, 5.2183e-06],\n",
      "        [2.3432e-01, 9.9998e-01, 1.5143e-01, 9.9630e-01, 1.6812e-03, 2.1840e-08,\n",
      "         3.2326e-01, 6.9581e-01, 1.8678e-04, 1.6310e-05],\n",
      "        [5.9356e-02, 5.3813e-09, 1.0000e+00, 2.1378e-08, 2.4399e-07, 9.9993e-01,\n",
      "         5.6344e-11, 9.9958e-01, 1.4835e-08, 1.1373e-12],\n",
      "        [9.9930e-01, 2.3017e-14, 1.0000e+00, 2.0545e-10, 1.3988e-01, 1.1429e-12,\n",
      "         3.2529e-15, 1.0000e+00, 1.9402e-07, 1.1800e-15],\n",
      "        [9.9998e-01, 7.3192e-12, 9.9922e-01, 1.0847e-05, 2.2013e-05, 3.0181e-01,\n",
      "         2.9865e-07, 9.9999e-01, 9.9991e-01, 6.6722e-09],\n",
      "        [3.3274e-03, 1.7121e-08, 9.9950e-01, 9.9999e-01, 3.8310e-09, 8.2971e-10,\n",
      "         3.1358e-06, 4.6309e-01, 1.0000e+00, 7.4128e-09],\n",
      "        [2.4579e-07, 3.7524e-08, 9.9937e-01, 9.9982e-01, 1.1412e-03, 6.8598e-08,\n",
      "         6.3430e-09, 5.4275e-01, 1.9192e-03, 1.4153e-09]]) tensor([[0., 1., 0., 1., 1., 1., 0., 1., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 0., 1., 0., 0., 1., 0., 0., 1., 1.],\n",
      "        [0., 1., 1., 0., 0., 1., 1., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 0., 0., 1.],\n",
      "        [1., 0., 1., 1., 0., 0., 1., 1., 0., 1.],\n",
      "        [0., 0., 1., 0., 1., 1., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [0., 1., 1., 1., 1., 0., 0., 1., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 0., 0., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 1., 0., 1., 0., 0., 1., 1., 0., 0.],\n",
      "        [1., 1., 0., 0., 1., 0., 1., 0., 0., 1.],\n",
      "        [1., 1., 1., 1., 0., 0., 1., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 1., 1., 0.],\n",
      "        [0., 1., 0., 1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 0., 1., 1.],\n",
      "        [0., 0., 1., 1., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
      "        [1., 0., 1., 1., 0., 0., 1., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 1., 1., 1., 0., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 0., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
      "        [0., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 0., 1., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 0., 1., 1., 0., 0., 1., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 1., 1., 0., 0., 0., 1., 1., 1.],\n",
      "        [0., 1., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 1., 0., 0., 1., 0., 0., 1., 1.],\n",
      "        [0., 1., 1., 1., 0., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 0., 0., 1., 1., 1., 1., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 0.],\n",
      "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 1., 0., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0., 1., 0.],\n",
      "        [0., 1., 1., 1., 0., 0., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 0., 1., 1., 1., 0., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 0., 1., 0., 1., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 1., 1., 1.],\n",
      "        [0., 1., 0., 0., 0., 1., 1., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 1., 1., 0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1., 1., 1., 0., 0., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 1., 0., 1., 1., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 1., 1., 0.]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(preds, y)\n\u001b[1;32m     12\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m criterion(preds\u001b[38;5;241m.\u001b[39mcuda(), y)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/DP/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DP/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    for batch, data in enumerate(train_dataloader):\n",
    "        x, y = data\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "               \n",
    "        z = model(x, y)\n",
    "        preds, _ = pipeline.transform(z.cpu().detach().numpy())\n",
    "        \n",
    "        print(preds, y)\n",
    "        train_loss = criterion(preds.cuda(), y)\n",
    "       \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            end = time.time()\n",
    "            loss, current = train_loss.item(), batch * len(x)\n",
    "            print(f'loss: {loss:>7f}  [{current:>5d}/{batch_size*len(x):>5d}] time: {end-start}')\n",
    "            start = time.time()\n",
    "\n",
    "    loss['train'].append(train_loss.data.item())\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in valid_dataloader:\n",
    "            x, y = data\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            \n",
    "            z = model(x, y)\n",
    "            preds, _ = pipeline.transform(z)\n",
    "            \n",
    "            val_loss = criterion(preds.cuda(), y)\n",
    "            \n",
    "    loss['valid'].append(val_loss.data.item())\n",
    "    \n",
    "    if loss['valid'][-1] < best_valid_loss:\n",
    "        torch.save(model.state_dict(), save_filename)\n",
    "        best_valid_loss = loss['valid'][-1]\n",
    "   \n",
    "    print(f'epoch [{epoch + 1}/{num_epochs}], loss:{loss[\"train\"][-1]}, valid_loss:{loss[\"valid\"][-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be38d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
