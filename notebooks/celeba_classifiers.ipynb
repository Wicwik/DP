{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f4c2174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "batch_size = 64\n",
    "best_valid_loss = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c87959e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_data = datasets.CelebA(root='data', split='train', download=True, transform=transform)\n",
    "valid_data = datasets.CelebA(root='data', split='valid', download=True, transform=transform)\n",
    "test_data = datasets.CelebA(root='data', split='test', download=True, transform=transform)\n",
    "\n",
    "features = ['Attractive', 'Eyeglasses', 'No_Beard', 'Male', 'Black_Hair', 'Blond_Hair', 'Mustache', 'Young', 'Smiling', 'Bald']\n",
    "names_data = train_data.attr_names\n",
    "idx = [names_data.index(x) for x in features]\n",
    "\n",
    "train_data.attr = train_data.attr[:,idx]\n",
    "valid_data.attr = valid_data.attr[:, idx]\n",
    "test_data.attr = test_data.attr[:, idx]\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c89ec40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.MultilabelResnetClassifier import MultilabelResnetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "985c7772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_nn import NNUtil\n",
    "\n",
    "model = MultilabelResnetClassifier(n_classes=len(features))\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "dataloaders={'train': train_dataloader, 'valid': valid_dataloader, 'test': test_dataloader}\n",
    "trainer = NNUtil(model=model, dataloaders=dataloaders, loss_fn=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52afd133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.798202  [    0/162770] time: 1.0570011138916016 acc: 0.4765625 precision: 0.3478260934352875 recall: 0.6296296119689941\n",
      "loss: 0.186934  [ 6400/162770] time: 16.13055729866028 acc: 0.9234374761581421 precision: 0.9122806787490845 recall: 0.8776371479034424\n",
      "loss: 0.163336  [12800/162770] time: 16.286580801010132 acc: 0.934374988079071 precision: 0.931034505367279 recall: 0.8925619721412659\n",
      "loss: 0.163681  [19200/162770] time: 16.218785047531128 acc: 0.934374988079071 precision: 0.9166666865348816 recall: 0.9090909361839294\n",
      "loss: 0.178405  [25600/162770] time: 16.258424758911133 acc: 0.9234374761581421 precision: 0.8986175060272217 recall: 0.8783783912658691\n",
      "loss: 0.177946  [32000/162770] time: 16.301422119140625 acc: 0.917187511920929 precision: 0.9035087823867798 recall: 0.8691983222961426\n",
      "loss: 0.162866  [38400/162770] time: 16.35820770263672 acc: 0.9312499761581421 precision: 0.8771186470985413 recall: 0.9324324131011963\n",
      "loss: 0.166863  [44800/162770] time: 16.289047718048096 acc: 0.925000011920929 precision: 0.9115044474601746 recall: 0.8803418874740601\n",
      "loss: 0.202442  [51200/162770] time: 16.395620346069336 acc: 0.9156249761581421 precision: 0.8695651888847351 recall: 0.8928571343421936\n",
      "loss: 0.143884  [57600/162770] time: 16.208619594573975 acc: 0.9453125 precision: 0.9066666960716248 recall: 0.9357798099517822\n",
      "loss: 0.140987  [64000/162770] time: 16.21932578086853 acc: 0.949999988079071 precision: 0.9198312163352966 recall: 0.9437229633331299\n",
      "loss: 0.163165  [70400/162770] time: 16.151315927505493 acc: 0.9312499761581421 precision: 0.873913049697876 recall: 0.9305555820465088\n",
      "loss: 0.214452  [76800/162770] time: 16.33927869796753 acc: 0.910937488079071 precision: 0.8425531983375549 recall: 0.9082568883895874\n",
      "loss: 0.134646  [83200/162770] time: 16.40643048286438 acc: 0.942187488079071 precision: 0.918181836605072 recall: 0.9140271544456482\n",
      "loss: 0.139279  [89600/162770] time: 16.224915266036987 acc: 0.940625011920929 precision: 0.8961039185523987 recall: 0.9366515874862671\n",
      "loss: 0.125849  [96000/162770] time: 16.218979597091675 acc: 0.9453125 precision: 0.926086962223053 recall: 0.9220778942108154\n",
      "loss: 0.134850  [102400/162770] time: 16.265307426452637 acc: 0.9390624761581421 precision: 0.9647576808929443 recall: 0.8759999871253967\n",
      "loss: 0.150155  [108800/162770] time: 16.15703558921814 acc: 0.925000011920929 precision: 0.8912134170532227 recall: 0.9063829779624939\n",
      "loss: 0.153044  [115200/162770] time: 16.356632471084595 acc: 0.9375 precision: 0.9254385828971863 recall: 0.9017093777656555\n",
      "loss: 0.136074  [121600/162770] time: 16.51404643058777 acc: 0.9437500238418579 precision: 0.9383260011672974 recall: 0.9063829779624939\n",
      "loss: 0.139163  [128000/162770] time: 16.225269079208374 acc: 0.9375 precision: 0.9247787594795227 recall: 0.9008620977401733\n",
      "loss: 0.134978  [134400/162770] time: 16.25507092475891 acc: 0.9375 precision: 0.9192824959754944 recall: 0.9030836820602417\n",
      "Valid | Error: \n",
      " Accuracy: 0.913802, Precision: 0.940626, Recall: 0.804805, Avg loss: 0.189919 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.140208  [    0/162770] time: 0.1724414825439453 acc: 0.9359375238418579 precision: 0.9025423526763916 recall: 0.9220778942108154\n",
      "loss: 0.199362  [ 6400/162770] time: 16.213176727294922 acc: 0.9140625 precision: 0.861751139163971 recall: 0.8820754885673523\n",
      "loss: 0.149201  [12800/162770] time: 16.25497341156006 acc: 0.9359375238418579 precision: 0.8961039185523987 recall: 0.9241071343421936\n",
      "loss: 0.127209  [19200/162770] time: 16.212705373764038 acc: 0.948437511920929 precision: 0.9264069199562073 recall: 0.9304347634315491\n",
      "loss: 0.169918  [25600/162770] time: 16.147758960723877 acc: 0.932812511920929 precision: 0.9213973879814148 recall: 0.8940678238868713\n",
      "loss: 0.141707  [32000/162770] time: 16.184008836746216 acc: 0.9437500238418579 precision: 0.9070796370506287 recall: 0.9318181872367859\n",
      "loss: 0.148174  [38400/162770] time: 16.211225509643555 acc: 0.9203125238418579 precision: 0.8706896305084229 recall: 0.9058296084403992\n",
      "loss: 0.135761  [44800/162770] time: 16.13692545890808 acc: 0.9437500238418579 precision: 0.9452054500579834 recall: 0.8961039185523987\n",
      "loss: 0.144856  [51200/162770] time: 16.20865273475647 acc: 0.940625011920929 precision: 0.9399141669273376 recall: 0.9012345671653748\n",
      "loss: 0.146449  [57600/162770] time: 16.241970539093018 acc: 0.9281250238418579 precision: 0.91629958152771 recall: 0.8851063847541809\n",
      "loss: 0.137608  [64000/162770] time: 16.30836510658264 acc: 0.942187488079071 precision: 0.8917748928070068 recall: 0.9449541568756104\n",
      "loss: 0.144047  [70400/162770] time: 16.327540636062622 acc: 0.934374988079071 precision: 0.8851063847541809 recall: 0.9327354431152344\n",
      "loss: 0.117028  [76800/162770] time: 16.30486035346985 acc: 0.949999988079071 precision: 0.9244444370269775 recall: 0.9327354431152344\n",
      "loss: 0.151004  [83200/162770] time: 16.337411880493164 acc: 0.9375 precision: 0.922374427318573 recall: 0.897777795791626\n",
      "loss: 0.128921  [89600/162770] time: 16.270216941833496 acc: 0.9453125 precision: 0.9342105388641357 recall: 0.9141631126403809\n",
      "loss: 0.149860  [96000/162770] time: 16.236090660095215 acc: 0.9281250238418579 precision: 0.9049773812294006 recall: 0.8888888955116272\n",
      "loss: 0.139924  [102400/162770] time: 16.22569227218628 acc: 0.9390624761581421 precision: 0.9072580933570862 recall: 0.9336099624633789\n",
      "loss: 0.134035  [108800/162770] time: 16.32573366165161 acc: 0.942187488079071 precision: 0.9292452931404114 recall: 0.8995434045791626\n",
      "loss: 0.118171  [115200/162770] time: 16.279781341552734 acc: 0.9515625238418579 precision: 0.9469026327133179 recall: 0.9184549450874329\n",
      "loss: 0.152823  [121600/162770] time: 16.30453395843506 acc: 0.932812511920929 precision: 0.8974359035491943 recall: 0.9170305728912354\n",
      "loss: 0.164907  [128000/162770] time: 16.28623342514038 acc: 0.9390624761581421 precision: 0.8995633125305176 recall: 0.9279279112815857\n",
      "loss: 0.148161  [134400/162770] time: 16.297940731048584 acc: 0.932812511920929 precision: 0.9110169410705566 recall: 0.9071729779243469\n",
      "loss: 0.123413  [140800/162770] time: 16.262579202651978 acc: 0.949999988079071 precision: 0.9487179517745972 recall: 0.9173553586006165\n",
      "loss: 0.133323  [147200/162770] time: 16.296558380126953 acc: 0.949999988079071 precision: 0.9447004795074463 recall: 0.9111111164093018\n",
      "loss: 0.124358  [153600/162770] time: 16.25408387184143 acc: 0.942187488079071 precision: 0.926086962223053 recall: 0.9141631126403809\n",
      "loss: 0.113783  [160000/162770] time: 16.262765407562256 acc: 0.957812488079071 precision: 0.9363636374473572 recall: 0.9406392574310303\n",
      "Valid | Error: \n",
      " Accuracy: 0.936976, Precision: 0.907278, Recall: 0.913409, Avg loss: 0.146366 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.121136  [    0/162770] time: 0.16713666915893555 acc: 0.9468749761581421 precision: 0.9192824959754944 recall: 0.9276018142700195\n",
      "loss: 0.123050  [ 6400/162770] time: 16.310996294021606 acc: 0.948437511920929 precision: 0.9113923907279968 recall: 0.9473684430122375\n",
      "loss: 0.137781  [12800/162770] time: 16.217334032058716 acc: 0.9359375238418579 precision: 0.918181836605072 recall: 0.897777795791626\n",
      "loss: 0.112091  [19200/162770] time: 16.28811526298523 acc: 0.948437511920929 precision: 0.9277108311653137 recall: 0.9390243887901306\n",
      "loss: 0.136805  [25600/162770] time: 16.336564779281616 acc: 0.9515625238418579 precision: 0.9485981464385986 recall: 0.9103139042854309\n",
      "loss: 0.133218  [32000/162770] time: 16.228320121765137 acc: 0.9437500238418579 precision: 0.8873873949050903 recall: 0.9471153616905212\n",
      "loss: 0.114527  [38400/162770] time: 16.209836959838867 acc: 0.953125 precision: 0.9267241358757019 recall: 0.9429824352264404\n",
      "loss: 0.134151  [44800/162770] time: 16.300904273986816 acc: 0.942187488079071 precision: 0.9227272868156433 recall: 0.9103139042854309\n",
      "loss: 0.129945  [51200/162770] time: 16.23598885536194 acc: 0.942187488079071 precision: 0.9141631126403809 recall: 0.926086962223053\n",
      "loss: 0.144896  [57600/162770] time: 16.283530473709106 acc: 0.9468749761581421 precision: 0.9200000166893005 recall: 0.9282511472702026\n",
      "loss: 0.121286  [64000/162770] time: 16.355331420898438 acc: 0.953125 precision: 0.90625 recall: 0.9575471878051758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.109885  [70400/162770] time: 16.285614728927612 acc: 0.9546874761581421 precision: 0.9636363387107849 recall: 0.9098712205886841\n",
      "loss: 0.100971  [76800/162770] time: 16.304107904434204 acc: 0.949999988079071 precision: 0.9601770043373108 recall: 0.9041666388511658\n",
      "loss: 0.138530  [83200/162770] time: 16.24916410446167 acc: 0.953125 precision: 0.9070796370506287 recall: 0.9579439163208008\n",
      "loss: 0.133780  [89600/162770] time: 16.294527530670166 acc: 0.9390624761581421 precision: 0.8893616795539856 recall: 0.9414414167404175\n",
      "loss: 0.131332  [96000/162770] time: 16.371323585510254 acc: 0.932812511920929 precision: 0.890350878238678 recall: 0.918552041053772\n",
      "loss: 0.118314  [102400/162770] time: 16.292105436325073 acc: 0.9546874761581421 precision: 0.9603524208068848 recall: 0.9159663915634155\n",
      "loss: 0.131064  [108800/162770] time: 16.250661373138428 acc: 0.940625011920929 precision: 0.9200000166893005 recall: 0.9118942618370056\n",
      "loss: 0.119914  [115200/162770] time: 16.335060119628906 acc: 0.9468749761581421 precision: 0.9264069199562073 recall: 0.9264069199562073\n",
      "loss: 0.097184  [121600/162770] time: 16.255265712738037 acc: 0.9593750238418579 precision: 0.9285714030265808 recall: 0.960869550704956\n",
      "loss: 0.116147  [128000/162770] time: 16.31910276412964 acc: 0.948437511920929 precision: 0.9327731132507324 recall: 0.9288703203201294\n",
      "loss: 0.137765  [134400/162770] time: 16.190449953079224 acc: 0.9359375238418579 precision: 0.8701298832893372 recall: 0.948113203048706\n",
      "loss: 0.118077  [140800/162770] time: 16.358471155166626 acc: 0.953125 precision: 0.904347836971283 recall: 0.9629629850387573\n",
      "loss: 0.167204  [147200/162770] time: 16.263640642166138 acc: 0.9281250238418579 precision: 0.8893616795539856 recall: 0.9126637578010559\n",
      "loss: 0.136045  [153600/162770] time: 16.081578969955444 acc: 0.940625011920929 precision: 0.8981481194496155 recall: 0.9238095283508301\n",
      "loss: 0.109030  [160000/162770] time: 16.088168621063232 acc: 0.948437511920929 precision: 0.9192824959754944 recall: 0.9318181872367859\n",
      "Valid | Error: \n",
      " Accuracy: 0.932479, Precision: 0.928633, Recall: 0.874408, Avg loss: 0.152662 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.129127  [    0/162770] time: 0.16666340827941895 acc: 0.9468749761581421 precision: 0.9304347634315491 recall: 0.9224137663841248\n",
      "loss: 0.124681  [ 6400/162770] time: 16.3535795211792 acc: 0.942187488079071 precision: 0.9047619104385376 recall: 0.9330357313156128\n",
      "loss: 0.100424  [12800/162770] time: 16.287073850631714 acc: 0.957812488079071 precision: 0.9588477611541748 recall: 0.9319999814033508\n",
      "loss: 0.134497  [19200/162770] time: 16.26810932159424 acc: 0.9468749761581421 precision: 0.9427312612533569 recall: 0.9106382727622986\n",
      "loss: 0.136065  [25600/162770] time: 16.268975734710693 acc: 0.9468749761581421 precision: 0.8974359035491943 recall: 0.9545454382896423\n",
      "loss: 0.140849  [32000/162770] time: 16.280885696411133 acc: 0.9375 precision: 0.9170305728912354 recall: 0.9090909361839294\n",
      "loss: 0.110710  [38400/162770] time: 16.238295555114746 acc: 0.948437511920929 precision: 0.9347826242446899 recall: 0.9227467775344849\n",
      "loss: 0.131780  [44800/162770] time: 16.33168339729309 acc: 0.9453125 precision: 0.9256198406219482 recall: 0.9294605851173401\n",
      "loss: 0.116174  [51200/162770] time: 16.2505624294281 acc: 0.949999988079071 precision: 0.9356223344802856 recall: 0.9276595711708069\n",
      "loss: 0.139580  [57600/162770] time: 16.266202926635742 acc: 0.9312499761581421 precision: 0.9017857313156128 recall: 0.9017857313156128\n",
      "loss: 0.097131  [64000/162770] time: 16.2065646648407 acc: 0.9609375 precision: 0.9466666579246521 recall: 0.9424778819084167\n",
      "loss: 0.125703  [70400/162770] time: 16.281094551086426 acc: 0.934374988079071 precision: 0.9144144058227539 recall: 0.8982300758361816\n",
      "loss: 0.138029  [76800/162770] time: 16.314274311065674 acc: 0.942187488079071 precision: 0.9233871102333069 recall: 0.9271255135536194\n",
      "loss: 0.141784  [83200/162770] time: 16.38927674293518 acc: 0.9281250238418579 precision: 0.8907563090324402 recall: 0.9137930870056152\n",
      "loss: 0.175118  [89600/162770] time: 16.275664806365967 acc: 0.926562488079071 precision: 0.8831775784492493 recall: 0.8957346081733704\n",
      "loss: 0.117450  [96000/162770] time: 16.22856569290161 acc: 0.9468749761581421 precision: 0.9115044474601746 recall: 0.9363636374473572\n",
      "loss: 0.141503  [102400/162770] time: 16.129050493240356 acc: 0.9375 precision: 0.9090909361839294 recall: 0.9090909361839294\n",
      "loss: 0.141327  [108800/162770] time: 16.185880184173584 acc: 0.9437500238418579 precision: 0.8865545988082886 recall: 0.9590908885002136\n",
      "loss: 0.088705  [115200/162770] time: 16.153757572174072 acc: 0.9624999761581421 precision: 0.9444444179534912 recall: 0.9525862336158752\n",
      "loss: 0.113977  [121600/162770] time: 16.399869680404663 acc: 0.957812488079071 precision: 0.9559471607208252 recall: 0.9273504018783569\n",
      "loss: 0.102794  [128000/162770] time: 16.389078855514526 acc: 0.9593750238418579 precision: 0.9678899049758911 recall: 0.917391300201416\n",
      "loss: 0.110858  [134400/162770] time: 16.35921812057495 acc: 0.9468749761581421 precision: 0.9227272868156433 recall: 0.9227272868156433\n",
      "loss: 0.132405  [140800/162770] time: 16.307315349578857 acc: 0.932812511920929 precision: 0.9012875556945801 recall: 0.9130434989929199\n",
      "loss: 0.111687  [147200/162770] time: 16.31389093399048 acc: 0.948437511920929 precision: 0.9446808695793152 recall: 0.9173553586006165\n",
      "loss: 0.117604  [153600/162770] time: 16.28451371192932 acc: 0.953125 precision: 0.9406779408454895 recall: 0.9327731132507324\n",
      "loss: 0.167824  [160000/162770] time: 16.37170934677124 acc: 0.9359375238418579 precision: 0.8990384340286255 recall: 0.9033816456794739\n",
      "Valid | Error: \n",
      " Accuracy: 0.933872, Precision: 0.890514, Recall: 0.924909, Avg loss: 0.156525 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.106249  [    0/162770] time: 0.1645526885986328 acc: 0.9515625238418579 precision: 0.9414414167404175 recall: 0.9207048416137695\n",
      "loss: 0.110663  [ 6400/162770] time: 16.1684730052948 acc: 0.9437500238418579 precision: 0.90625 recall: 0.9311926364898682\n",
      "loss: 0.110849  [12800/162770] time: 16.27271318435669 acc: 0.9437500238418579 precision: 0.9252336621284485 recall: 0.9082568883895874\n",
      "loss: 0.115673  [19200/162770] time: 16.287882804870605 acc: 0.9437500238418579 precision: 0.9234042763710022 recall: 0.9234042763710022\n",
      "loss: 0.118005  [25600/162770] time: 16.25409245491028 acc: 0.9437500238418579 precision: 0.9066666960716248 recall: 0.931506872177124\n",
      "loss: 0.107292  [32000/162770] time: 16.3659188747406 acc: 0.9624999761581421 precision: 0.9347826242446899 recall: 0.9598214030265808\n",
      "loss: 0.105308  [38400/162770] time: 16.204222679138184 acc: 0.9515625238418579 precision: 0.9382715821266174 recall: 0.9344262480735779\n",
      "loss: 0.134436  [44800/162770] time: 16.293807983398438 acc: 0.9515625238418579 precision: 0.9051724076271057 recall: 0.9589040875434875\n",
      "loss: 0.107067  [51200/162770] time: 16.368701934814453 acc: 0.953125 precision: 0.9304347634315491 recall: 0.9385964870452881\n",
      "loss: 0.108514  [57600/162770] time: 16.35274386405945 acc: 0.9593750238418579 precision: 0.9301310181617737 recall: 0.9551569223403931\n",
      "loss: 0.104971  [64000/162770] time: 16.466408491134644 acc: 0.9609375 precision: 0.9603524208068848 recall: 0.9316239356994629\n",
      "loss: 0.107701  [70400/162770] time: 16.40285086631775 acc: 0.9546874761581421 precision: 0.9475982785224915 recall: 0.9273504018783569\n",
      "loss: 0.106435  [76800/162770] time: 16.31372904777527 acc: 0.953125 precision: 0.9234042763710022 recall: 0.9475982785224915\n",
      "loss: 0.113039  [83200/162770] time: 16.33993172645569 acc: 0.9515625238418579 precision: 0.9336099624633789 recall: 0.9375\n",
      "loss: 0.108258  [89600/162770] time: 16.26369857788086 acc: 0.9609375 precision: 0.9770641922950745 recall: 0.9141631126403809\n",
      "loss: 0.094860  [96000/162770] time: 16.27296781539917 acc: 0.9609375 precision: 0.9525862336158752 recall: 0.9404255151748657\n",
      "loss: 0.103653  [102400/162770] time: 16.215858936309814 acc: 0.9609375 precision: 0.9383260011672974 recall: 0.9508928656578064\n",
      "loss: 0.134665  [108800/162770] time: 16.147947788238525 acc: 0.9437500238418579 precision: 0.9230769276618958 recall: 0.9147982001304626\n",
      "loss: 0.122820  [115200/162770] time: 16.14542865753174 acc: 0.9546874761581421 precision: 0.9517543911933899 recall: 0.9234042763710022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.142113  [121600/162770] time: 16.22463369369507 acc: 0.9312499761581421 precision: 0.9066666960716248 recall: 0.8986784219741821\n",
      "loss: 0.097096  [128000/162770] time: 16.296155214309692 acc: 0.957812488079071 precision: 0.9099099040031433 recall: 0.9665071964263916\n",
      "loss: 0.126117  [134400/162770] time: 16.2146315574646 acc: 0.9390624761581421 precision: 0.9354838728904724 recall: 0.890350878238678\n",
      "loss: 0.137261  [140800/162770] time: 16.25610065460205 acc: 0.9296875 precision: 0.90625 recall: 0.8942731022834778\n",
      "loss: 0.116505  [147200/162770] time: 16.192627429962158 acc: 0.932812511920929 precision: 0.8918918967247009 recall: 0.9124423861503601\n",
      "loss: 0.095605  [153600/162770] time: 16.205593824386597 acc: 0.9609375 precision: 0.9375 recall: 0.9502262473106384\n",
      "loss: 0.156612  [160000/162770] time: 16.24087619781494 acc: 0.934374988079071 precision: 0.8878923654556274 recall: 0.9209302067756653\n",
      "Valid | Error: \n",
      " Accuracy: 0.932275, Precision: 0.920943, Recall: 0.882534, Avg loss: 0.159214 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.090804  [    0/162770] time: 0.16654539108276367 acc: 0.9593750238418579 precision: 0.9624413251876831 recall: 0.9192824959754944\n",
      "loss: 0.106033  [ 6400/162770] time: 16.34887957572937 acc: 0.9546874761581421 precision: 0.9156118035316467 recall: 0.9601770043373108\n",
      "loss: 0.090620  [12800/162770] time: 16.25919222831726 acc: 0.9609375 precision: 0.9254385828971863 recall: 0.9634703397750854\n",
      "loss: 0.099181  [19200/162770] time: 16.25919246673584 acc: 0.957812488079071 precision: 0.9547511339187622 recall: 0.9254385828971863\n",
      "loss: 0.104980  [25600/162770] time: 16.36726713180542 acc: 0.9515625238418579 precision: 0.9424778819084167 recall: 0.9220778942108154\n",
      "loss: 0.095743  [32000/162770] time: 16.47718834877014 acc: 0.957812488079071 precision: 0.9650654792785645 recall: 0.9208333492279053\n",
      "loss: 0.060151  [38400/162770] time: 16.399972677230835 acc: 0.9765625 precision: 0.9821428656578064 recall: 0.9523809552192688\n",
      "loss: 0.078700  [44800/162770] time: 16.319392442703247 acc: 0.9671875238418579 precision: 0.9515418410301208 recall: 0.9557521939277649\n",
      "loss: 0.104866  [51200/162770] time: 16.241429328918457 acc: 0.9453125 precision: 0.931506872177124 recall: 0.9107142686843872\n",
      "loss: 0.106024  [57600/162770] time: 16.37370753288269 acc: 0.9468749761581421 precision: 0.9279279112815857 recall: 0.9196428656578064\n",
      "loss: 0.123756  [64000/162770] time: 16.20474338531494 acc: 0.9453125 precision: 0.8947368264198303 recall: 0.9488372206687927\n",
      "loss: 0.065684  [70400/162770] time: 16.307047367095947 acc: 0.9781249761581421 precision: 0.9563318490982056 recall: 0.9820627570152283\n",
      "loss: 0.121227  [76800/162770] time: 16.308165788650513 acc: 0.948437511920929 precision: 0.9082568883895874 recall: 0.9383886456489563\n",
      "loss: 0.086264  [83200/162770] time: 16.329692363739014 acc: 0.964062511920929 precision: 0.9262672662734985 recall: 0.9663461446762085\n",
      "loss: 0.097518  [89600/162770] time: 16.318618059158325 acc: 0.957812488079071 precision: 0.9237288236618042 recall: 0.9603524208068848\n",
      "loss: 0.074404  [96000/162770] time: 16.327677011489868 acc: 0.971875011920929 precision: 0.9551569223403931 recall: 0.9638009071350098\n",
      "loss: 0.092765  [102400/162770] time: 16.314486265182495 acc: 0.9593750238418579 precision: 0.9610389471054077 recall: 0.9288703203201294\n",
      "loss: 0.087774  [108800/162770] time: 16.386010885238647 acc: 0.9609375 precision: 0.9244444370269775 recall: 0.9629629850387573\n",
      "loss: 0.114991  [115200/162770] time: 16.34381127357483 acc: 0.9546874761581421 precision: 0.9357798099517822 recall: 0.931506872177124\n",
      "loss: 0.106315  [121600/162770] time: 16.307843446731567 acc: 0.9468749761581421 precision: 0.9434782862663269 recall: 0.9117646813392639\n",
      "loss: 0.102742  [128000/162770] time: 16.35708522796631 acc: 0.9624999761581421 precision: 0.9603524208068848 recall: 0.9356223344802856\n",
      "loss: 0.090138  [134400/162770] time: 16.285480976104736 acc: 0.9609375 precision: 0.9279661178588867 recall: 0.9647576808929443\n",
      "loss: 0.135587  [140800/162770] time: 16.185062646865845 acc: 0.9437500238418579 precision: 0.9307359457015991 recall: 0.914893627166748\n",
      "loss: 0.096774  [147200/162770] time: 16.238379955291748 acc: 0.953125 precision: 0.9282511472702026 recall: 0.9366515874862671\n",
      "loss: 0.080387  [153600/162770] time: 16.392513751983643 acc: 0.965624988079071 precision: 0.9427312612533569 recall: 0.9596412777900696\n",
      "loss: 0.082591  [160000/162770] time: 16.48301362991333 acc: 0.9703124761581421 precision: 0.9585253596305847 recall: 0.9541284441947937\n",
      "Valid | Error: \n",
      " Accuracy: 0.935984, Precision: 0.904046, Recall: 0.914255, Avg loss: 0.158299 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.053263  [    0/162770] time: 0.16654038429260254 acc: 0.9750000238418579 precision: 0.9652174115180969 recall: 0.9652174115180969\n",
      "loss: 0.061877  [ 6400/162770] time: 16.394145488739014 acc: 0.973437488079071 precision: 0.9770641922950745 recall: 0.9466666579246521\n",
      "loss: 0.079745  [12800/162770] time: 16.318470001220703 acc: 0.9624999761581421 precision: 0.9642857313156128 recall: 0.931034505367279\n",
      "loss: 0.063837  [19200/162770] time: 16.209533214569092 acc: 0.9781249761581421 precision: 0.9770641922950745 recall: 0.9594594836235046\n",
      "loss: 0.072863  [25600/162770] time: 16.361621856689453 acc: 0.965624988079071 precision: 0.9599999785423279 recall: 0.943231463432312\n",
      "loss: 0.060518  [32000/162770] time: 16.296979665756226 acc: 0.9781249761581421 precision: 0.9513274431228638 recall: 0.9862385392189026\n",
      "loss: 0.100860  [38400/162770] time: 16.48507046699524 acc: 0.9609375 precision: 0.9672897458076477 recall: 0.9200000166893005\n",
      "loss: 0.074653  [44800/162770] time: 16.40319561958313 acc: 0.9624999761581421 precision: 0.9434782862663269 recall: 0.9517543911933899\n",
      "loss: 0.082486  [51200/162770] time: 16.239689111709595 acc: 0.9624999761581421 precision: 0.9267241358757019 recall: 0.9684684872627258\n",
      "loss: 0.078337  [57600/162770] time: 16.236487865447998 acc: 0.9703124761581421 precision: 0.9652174115180969 recall: 0.9527897238731384\n",
      "loss: 0.084805  [64000/162770] time: 16.303539991378784 acc: 0.956250011920929 precision: 0.9457013607025146 recall: 0.9288889169692993\n",
      "loss: 0.085378  [70400/162770] time: 16.261225700378418 acc: 0.9593750238418579 precision: 0.9439252614974976 recall: 0.9351851940155029\n",
      "loss: 0.078630  [76800/162770] time: 16.327874898910522 acc: 0.979687511920929 precision: 0.9688888788223267 recall: 0.9732142686843872\n",
      "loss: 0.076536  [83200/162770] time: 16.319151401519775 acc: 0.96875 precision: 0.9652174115180969 recall: 0.9487179517745972\n",
      "loss: 0.070317  [89600/162770] time: 16.24207329750061 acc: 0.96875 precision: 0.9521738886833191 recall: 0.9605262875556946\n",
      "loss: 0.083950  [96000/162770] time: 16.241596937179565 acc: 0.9671875238418579 precision: 0.9469026327133179 recall: 0.9596412777900696\n",
      "loss: 0.062467  [102400/162770] time: 16.21081042289734 acc: 0.9703124761581421 precision: 0.9539749026298523 recall: 0.9661017060279846\n",
      "loss: 0.093989  [108800/162770] time: 16.134979486465454 acc: 0.9593750238418579 precision: 0.9631336331367493 recall: 0.9207048416137695\n",
      "loss: 0.092132  [115200/162770] time: 16.321678638458252 acc: 0.9624999761581421 precision: 0.9646017551422119 recall: 0.9316239356994629\n",
      "loss: 0.069109  [121600/162770] time: 16.362241506576538 acc: 0.9765625 precision: 0.9652174115180969 recall: 0.9694322943687439\n",
      "loss: 0.059087  [128000/162770] time: 16.288484573364258 acc: 0.973437488079071 precision: 0.9502262473106384 recall: 0.9722222089767456\n",
      "loss: 0.072354  [134400/162770] time: 16.37465000152588 acc: 0.9671875238418579 precision: 0.9517543911933899 recall: 0.9559471607208252\n",
      "loss: 0.109978  [140800/162770] time: 16.34400773048401 acc: 0.9546874761581421 precision: 0.9601770043373108 recall: 0.9156118035316467\n",
      "loss: 0.057218  [147200/162770] time: 16.25880527496338 acc: 0.9703124761581421 precision: 0.9618644118309021 recall: 0.9578059315681458\n",
      "loss: 0.076479  [153600/162770] time: 16.299802541732788 acc: 0.9671875238418579 precision: 0.9557521939277649 recall: 0.9515418410301208\n",
      "loss: 0.079198  [160000/162770] time: 16.311611652374268 acc: 0.9750000238418579 precision: 0.9737991094589233 recall: 0.9570815563201904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | Error: \n",
      " Accuracy: 0.934234, Precision: 0.910748, Recall: 0.900396, Avg loss: 0.178436 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.063598  [    0/162770] time: 0.17516446113586426 acc: 0.971875011920929 precision: 0.9819819927215576 recall: 0.9396551847457886\n",
      "loss: 0.042954  [ 6400/162770] time: 16.49529480934143 acc: 0.9781249761581421 precision: 0.9647576808929443 recall: 0.9733333587646484\n",
      "loss: 0.039503  [12800/162770] time: 16.35405158996582 acc: 0.984375 precision: 0.9779735803604126 recall: 0.9779735803604126\n",
      "loss: 0.052340  [19200/162770] time: 16.2877140045166 acc: 0.981249988079071 precision: 0.9700854420661926 recall: 0.9784482717514038\n",
      "loss: 0.048510  [25600/162770] time: 16.280375242233276 acc: 0.981249988079071 precision: 0.9830508232116699 recall: 0.9666666388511658\n",
      "loss: 0.047752  [32000/162770] time: 16.29220700263977 acc: 0.9828125238418579 precision: 0.9732142686843872 recall: 0.9775784611701965\n",
      "loss: 0.060462  [38400/162770] time: 16.461535215377808 acc: 0.96875 precision: 0.9641255736351013 recall: 0.9471365809440613\n",
      "loss: 0.060159  [44800/162770] time: 16.360188722610474 acc: 0.981249988079071 precision: 0.9824561476707458 recall: 0.9655172228813171\n",
      "loss: 0.039855  [51200/162770] time: 16.335566759109497 acc: 0.9828125238418579 precision: 0.9816513657569885 recall: 0.9683257937431335\n",
      "loss: 0.049355  [57600/162770] time: 16.277875900268555 acc: 0.979687511920929 precision: 0.9779735803604126 recall: 0.9652174115180969\n",
      "loss: 0.070615  [64000/162770] time: 16.339745044708252 acc: 0.9703124761581421 precision: 0.9506726264953613 recall: 0.9636363387107849\n",
      "loss: 0.058085  [70400/162770] time: 16.239722728729248 acc: 0.9781249761581421 precision: 0.981566846370697 recall: 0.9551569223403931\n",
      "loss: 0.054844  [76800/162770] time: 16.475607872009277 acc: 0.9750000238418579 precision: 0.9655172228813171 recall: 0.9655172228813171\n",
      "loss: 0.078623  [83200/162770] time: 16.34504771232605 acc: 0.9671875238418579 precision: 0.9375 recall: 0.9677419066429138\n",
      "loss: 0.071281  [89600/162770] time: 16.357555866241455 acc: 0.971875011920929 precision: 0.9734513163566589 recall: 0.9482758641242981\n",
      "loss: 0.063098  [96000/162770] time: 16.322806358337402 acc: 0.973437488079071 precision: 0.9737991094589233 recall: 0.9529914259910583\n",
      "loss: 0.038322  [102400/162770] time: 16.391345024108887 acc: 0.984375 precision: 0.9818181991577148 recall: 0.9729729890823364\n",
      "loss: 0.079281  [108800/162770] time: 16.366186380386353 acc: 0.9671875238418579 precision: 0.9670782089233398 recall: 0.9475806355476379\n",
      "loss: 0.056383  [115200/162770] time: 16.3962459564209 acc: 0.9765625 precision: 0.9702127575874329 recall: 0.9661017060279846\n",
      "loss: 0.072917  [121600/162770] time: 16.28369140625 acc: 0.9765625 precision: 0.9457013607025146 recall: 0.9858490824699402\n",
      "loss: 0.067287  [128000/162770] time: 16.339356899261475 acc: 0.9703124761581421 precision: 0.9515418410301208 recall: 0.9642857313156128\n",
      "loss: 0.069668  [134400/162770] time: 16.403515815734863 acc: 0.9703124761581421 precision: 0.934883713722229 recall: 0.9757281541824341\n",
      "loss: 0.062489  [140800/162770] time: 16.386595010757446 acc: 0.9781249761581421 precision: 0.9680365324020386 recall: 0.9680365324020386\n",
      "loss: 0.060468  [147200/162770] time: 16.23202395439148 acc: 0.973437488079071 precision: 0.9729729890823364 recall: 0.9515418410301208\n",
      "loss: 0.074396  [153600/162770] time: 16.298548221588135 acc: 0.96875 precision: 0.9742489457130432 recall: 0.9419087171554565\n",
      "loss: 0.085183  [160000/162770] time: 16.29077935218811 acc: 0.964062511920929 precision: 0.9773755669593811 recall: 0.9230769276618958\n",
      "Valid | Error: \n",
      " Accuracy: 0.917233, Precision: 0.929938, Recall: 0.826008, Avg loss: 0.256112 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.039158  [    0/162770] time: 0.17198562622070312 acc: 0.9859374761581421 precision: 0.9820627570152283 recall: 0.9776785969734192\n",
      "loss: 0.046137  [ 6400/162770] time: 16.2259738445282 acc: 0.9859374761581421 precision: 0.9739130139350891 recall: 0.9867841601371765\n",
      "loss: 0.036277  [12800/162770] time: 16.228804111480713 acc: 0.9859374761581421 precision: 0.9868420958518982 recall: 0.9740259647369385\n",
      "loss: 0.038622  [19200/162770] time: 16.17848038673401 acc: 0.987500011920929 precision: 0.9672897458076477 recall: 0.995192289352417\n",
      "loss: 0.036251  [25600/162770] time: 16.158354997634888 acc: 0.989062488079071 precision: 0.9686098694801331 recall: 1.0\n",
      "loss: 0.043585  [32000/162770] time: 16.20086407661438 acc: 0.9828125238418579 precision: 0.9690265655517578 recall: 0.9820627570152283\n",
      "loss: 0.044907  [38400/162770] time: 16.282063484191895 acc: 0.9828125238418579 precision: 0.9833333492279053 recall: 0.9711934328079224\n",
      "loss: 0.046111  [44800/162770] time: 16.21614933013916 acc: 0.9828125238418579 precision: 0.9910714030265808 recall: 0.9610389471054077\n",
      "loss: 0.045996  [51200/162770] time: 16.24672222137451 acc: 0.9781249761581421 precision: 0.9545454382896423 recall: 0.9813084006309509\n",
      "loss: 0.053191  [57600/162770] time: 16.179107666015625 acc: 0.984375 precision: 0.9914529919624329 recall: 0.9666666388511658\n",
      "loss: 0.042430  [64000/162770] time: 16.259629726409912 acc: 0.9859374761581421 precision: 0.9780701994895935 recall: 0.9823788404464722\n",
      "loss: 0.054496  [70400/162770] time: 16.187277793884277 acc: 0.9750000238418579 precision: 0.9776785969734192 recall: 0.9521738886833191\n",
      "loss: 0.036009  [76800/162770] time: 16.320475816726685 acc: 0.9906250238418579 precision: 0.9870129823684692 recall: 0.9870129823684692\n",
      "loss: 0.038352  [83200/162770] time: 16.32868456840515 acc: 0.981249988079071 precision: 0.9659574627876282 recall: 0.9826839566230774\n",
      "loss: 0.030101  [89600/162770] time: 16.350858688354492 acc: 0.989062488079071 precision: 1.0 recall: 0.969298243522644\n",
      "loss: 0.045624  [96000/162770] time: 16.41794228553772 acc: 0.979687511920929 precision: 0.9624999761581421 recall: 0.9829787015914917\n",
      "loss: 0.036184  [102400/162770] time: 16.299541234970093 acc: 0.9906250238418579 precision: 0.9909090995788574 recall: 0.9819819927215576\n",
      "loss: 0.039501  [108800/162770] time: 16.49121069908142 acc: 0.989062488079071 precision: 0.9730941653251648 recall: 0.9954128265380859\n",
      "loss: 0.033270  [115200/162770] time: 16.173689365386963 acc: 0.989062488079071 precision: 0.9824561476707458 recall: 0.9867841601371765\n",
      "loss: 0.039431  [121600/162770] time: 16.272361040115356 acc: 0.984375 precision: 0.9824561476707458 recall: 0.9739130139350891\n",
      "loss: 0.057311  [128000/162770] time: 16.210805416107178 acc: 0.9765625 precision: 0.9578059315681458 recall: 0.9784482717514038\n",
      "loss: 0.062824  [134400/162770] time: 16.2239511013031 acc: 0.9765625 precision: 0.9728506803512573 recall: 0.9598214030265808\n",
      "loss: 0.049280  [140800/162770] time: 16.101451635360718 acc: 0.981249988079071 precision: 0.977477490901947 recall: 0.96875\n",
      "loss: 0.066920  [147200/162770] time: 16.229241609573364 acc: 0.9765625 precision: 0.9629629850387573 recall: 0.9674418568611145\n",
      "loss: 0.088256  [153600/162770] time: 16.302724599838257 acc: 0.9671875238418579 precision: 0.957446813583374 recall: 0.9533898234367371\n",
      "loss: 0.057064  [160000/162770] time: 16.338958740234375 acc: 0.9765625 precision: 0.959276020526886 recall: 0.9724770784378052\n",
      "Valid | Error: \n",
      " Accuracy: 0.930604, Precision: 0.881809, Recall: 0.926102, Avg loss: 0.255439 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.033113  [    0/162770] time: 0.17444968223571777 acc: 0.9859374761581421 precision: 0.9699570536613464 recall: 0.9912280440330505\n",
      "loss: 0.021515  [ 6400/162770] time: 16.28009009361267 acc: 0.9906250238418579 precision: 0.9915611743927002 recall: 0.9832636117935181\n",
      "loss: 0.038085  [12800/162770] time: 16.301146745681763 acc: 0.984375 precision: 0.9783549904823303 recall: 0.9783549904823303\n",
      "loss: 0.029694  [19200/162770] time: 16.35500717163086 acc: 0.984375 precision: 0.9656652212142944 recall: 0.9911894202232361\n",
      "loss: 0.040412  [25600/162770] time: 16.361563205718994 acc: 0.987500011920929 precision: 0.9792531132698059 recall: 0.9874476790428162\n",
      "loss: 0.026472  [32000/162770] time: 16.28695011138916 acc: 0.987500011920929 precision: 0.9867841601371765 recall: 0.9781659245491028\n",
      "loss: 0.018305  [38400/162770] time: 16.34870219230652 acc: 0.995312511920929 precision: 0.990867555141449 recall: 0.9954128265380859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.028769  [44800/162770] time: 16.40094304084778 acc: 0.987500011920929 precision: 0.9872881174087524 recall: 0.9789915680885315\n",
      "loss: 0.047316  [51200/162770] time: 16.318308115005493 acc: 0.984375 precision: 0.9736841917037964 recall: 0.982300877571106\n",
      "loss: 0.047358  [57600/162770] time: 16.224337577819824 acc: 0.979687511920929 precision: 0.9656652212142944 recall: 0.97826087474823\n",
      "loss: 0.027161  [64000/162770] time: 16.14490818977356 acc: 0.9937499761581421 precision: 0.9954751133918762 recall: 0.9865471124649048\n",
      "loss: 0.035526  [70400/162770] time: 16.355412483215332 acc: 0.984375 precision: 0.9746835231781006 recall: 0.9829787015914917\n",
      "loss: 0.048794  [76800/162770] time: 16.2732093334198 acc: 0.9828125238418579 precision: 0.960869550704956 recall: 0.9910314083099365\n",
      "loss: 0.035678  [83200/162770] time: 16.362791299819946 acc: 0.9859374761581421 precision: 0.9831932783126831 recall: 0.9790794849395752\n",
      "loss: 0.037051  [89600/162770] time: 16.373429775238037 acc: 0.9828125238418579 precision: 0.9739130139350891 recall: 0.9781659245491028\n",
      "loss: 0.045696  [96000/162770] time: 16.27924370765686 acc: 0.9828125238418579 precision: 0.978723406791687 recall: 0.9745762944221497\n",
      "loss: 0.040491  [102400/162770] time: 16.31340527534485 acc: 0.9828125238418579 precision: 0.9704641103744507 recall: 0.9829059839248657\n",
      "loss: 0.046039  [108800/162770] time: 16.36973261833191 acc: 0.9828125238418579 precision: 0.9820627570152283 recall: 0.9690265655517578\n",
      "loss: 0.041461  [115200/162770] time: 16.40030336380005 acc: 0.9859374761581421 precision: 0.9817351698875427 recall: 0.9772727489471436\n",
      "loss: 0.033751  [121600/162770] time: 16.377336025238037 acc: 0.989062488079071 precision: 0.9910714030265808 recall: 0.9779735803604126\n",
      "loss: 0.043323  [128000/162770] time: 16.381290674209595 acc: 0.981249988079071 precision: 0.9732142686843872 recall: 0.9732142686843872\n",
      "loss: 0.062744  [134400/162770] time: 16.43754482269287 acc: 0.9781249761581421 precision: 0.9626168012619019 recall: 0.9716981053352356\n",
      "loss: 0.042016  [140800/162770] time: 16.311723232269287 acc: 0.979687511920929 precision: 0.9864253401756287 recall: 0.9561403393745422\n",
      "loss: 0.018026  [147200/162770] time: 16.41911220550537 acc: 0.995312511920929 precision: 1.0 recall: 0.9871794581413269\n",
      "loss: 0.045003  [153600/162770] time: 16.38384461402893 acc: 0.984375 precision: 0.9819004535675049 recall: 0.9730941653251648\n",
      "loss: 0.046109  [160000/162770] time: 16.320446491241455 acc: 0.9828125238418579 precision: 0.9806763529777527 recall: 0.9666666388511658\n",
      "Valid | Error: \n",
      " Accuracy: 0.926303, Precision: 0.911648, Recall: 0.874286, Avg loss: 0.264319 \n",
      "\n",
      "Done!\n",
      "Test | Error: \n",
      " Accuracy: 0.925888, Precision: 0.911632, Recall: 0.874516, Avg loss: 0.264641 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14cd6152",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer._NNUtil__model.state_dict(), \"resnet34_celeba10attr_10e.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efbe9fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultilabelResnetClassifier(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=512, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer._NNUtil__model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d65f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
