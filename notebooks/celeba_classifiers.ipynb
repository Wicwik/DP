{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f4c2174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c87959e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "best_valid_loss = np.inf\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_data = datasets.CelebA(root='data', split='train', download=True, transform=transform)\n",
    "valid_data = datasets.CelebA(root='data', split='valid', download=True, transform=transform)\n",
    "test_data = datasets.CelebA(root='data', split='test', download=True, transform=transform)\n",
    "\n",
    "features = ['Attractive', 'Eyeglasses', 'No_Beard', 'Male', 'Black_Hair', 'Blond_Hair', 'Mustache', 'Young', 'Smiling', 'Bald']\n",
    "names_data = train_data.attr_names\n",
    "idx = [names_data.index(x) for x in features]\n",
    "\n",
    "train_data.attr = train_data.attr[:,idx]\n",
    "valid_data.attr = valid_data.attr[:, idx]\n",
    "test_data.attr = test_data.attr[:, idx]\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "985c7772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/wicwik/pytorch-resnet34-classifier/af5d78196ae74640b10b8b6e0e9df240\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.844471  [    0/162770] time: 1.3008537292480469 acc: 0.37187498807907104 precision: 0.34300729632377625 recall: 0.6830494403839111, f1_macro: 0.3440707325935364\n",
      "loss: 0.206048  [ 6400/162770] time: 18.91797137260437 acc: 0.9203125238418579 precision: 0.8298611640930176 recall: 0.7749924063682556, f1_macro: 0.7920374274253845\n",
      "loss: 0.203863  [12800/162770] time: 18.531570434570312 acc: 0.9046874642372131 precision: 0.7533761262893677 recall: 0.7091480493545532, f1_macro: 0.7005952000617981\n",
      "loss: 0.206746  [19200/162770] time: 18.687729835510254 acc: 0.9140625596046448 precision: 0.850766658782959 recall: 0.8040753602981567, f1_macro: 0.821570634841919\n",
      "loss: 0.196587  [25600/162770] time: 18.514316082000732 acc: 0.9234374165534973 precision: 0.6608806252479553 recall: 0.7095963954925537, f1_macro: 0.6732354760169983\n",
      "loss: 0.177726  [32000/162770] time: 18.762848377227783 acc: 0.9218749403953552 precision: 0.7724224925041199 recall: 0.8074849843978882, f1_macro: 0.7846113443374634\n",
      "loss: 0.148885  [38400/162770] time: 18.806403398513794 acc: 0.9328125715255737 precision: 0.8132350444793701 recall: 0.8235018253326416, f1_macro: 0.8089063167572021\n",
      "loss: 0.144112  [44800/162770] time: 18.97414803504944 acc: 0.9390624165534973 precision: 0.7953922152519226 recall: 0.7921582460403442, f1_macro: 0.7682828903198242\n",
      "loss: 0.148713  [51200/162770] time: 18.830045223236084 acc: 0.9390625357627869 precision: 0.7432447671890259 recall: 0.7044009566307068, f1_macro: 0.7217799425125122\n",
      "loss: 0.138684  [57600/162770] time: 18.371288299560547 acc: 0.940625011920929 precision: 0.8345566391944885 recall: 0.7410488724708557, f1_macro: 0.7574605941772461\n",
      "loss: 0.147241  [64000/162770] time: 18.665518760681152 acc: 0.9359375238418579 precision: 0.7269271612167358 recall: 0.7291300892829895, f1_macro: 0.7228121161460876\n",
      "loss: 0.160356  [70400/162770] time: 18.720088720321655 acc: 0.9328124523162842 precision: 0.9134653210639954 recall: 0.7567377686500549, f1_macro: 0.8000190258026123\n",
      "loss: 0.142031  [76800/162770] time: 18.92102837562561 acc: 0.942187488079071 precision: 0.8220605254173279 recall: 0.7760068774223328, f1_macro: 0.7893234491348267\n",
      "loss: 0.144920  [83200/162770] time: 19.141754865646362 acc: 0.934374988079071 precision: 0.8105257153511047 recall: 0.7933045625686646, f1_macro: 0.7903818488121033\n",
      "loss: 0.142214  [89600/162770] time: 20.005897998809814 acc: 0.9421876072883606 precision: 0.9612135291099548 recall: 0.8470968008041382, f1_macro: 0.8872650265693665\n",
      "loss: 0.166953  [96000/162770] time: 18.641303777694702 acc: 0.9296875 precision: 0.829014778137207 recall: 0.8642797470092773, f1_macro: 0.8117361068725586\n",
      "loss: 0.157788  [102400/162770] time: 19.00014328956604 acc: 0.9406249523162842 precision: 0.8762388229370117 recall: 0.8788609504699707, f1_macro: 0.8628920912742615\n",
      "loss: 0.150969  [108800/162770] time: 19.060294151306152 acc: 0.9312499761581421 precision: 0.8818070292472839 recall: 0.8809854984283447, f1_macro: 0.8712888956069946\n",
      "loss: 0.145038  [115200/162770] time: 19.185425996780396 acc: 0.926562488079071 precision: 0.844394326210022 recall: 0.7867574691772461, f1_macro: 0.81236732006073\n",
      "loss: 0.170338  [121600/162770] time: 19.008566856384277 acc: 0.9187499284744263 precision: 0.8087133765220642 recall: 0.7341481447219849, f1_macro: 0.7657608389854431\n",
      "loss: 0.167070  [128000/162770] time: 19.249770641326904 acc: 0.9234374165534973 precision: 0.697209894657135 recall: 0.7287623882293701, f1_macro: 0.6973705887794495\n",
      "loss: 0.127111  [134400/162770] time: 19.18196725845337 acc: 0.9531250596046448 precision: 0.9288105964660645 recall: 0.8517904281616211, f1_macro: 0.8625015616416931\n",
      "loss: 0.171672  [140800/162770] time: 18.844770908355713 acc: 0.9375 precision: 0.8425323367118835 recall: 0.7608788013458252, f1_macro: 0.7805659770965576\n",
      "loss: 0.156938  [147200/162770] time: 18.95996403694153 acc: 0.918749988079071 precision: 0.7515648007392883 recall: 0.7301895618438721, f1_macro: 0.7392717599868774\n",
      "loss: 0.141267  [153600/162770] time: 18.869457006454468 acc: 0.9265624284744263 precision: 0.9157697558403015 recall: 0.8659369945526123, f1_macro: 0.8820927143096924\n",
      "loss: 0.172881  [160000/162770] time: 18.94551706314087 acc: 0.9187500476837158 precision: 0.686690628528595 recall: 0.7382190227508545, f1_macro: 0.7089076638221741\n",
      "Valid | Error: \n",
      " Accuracy: 0.916400, Precision: 0.761681, Recall: 0.778061, Avg loss: 0.222948, F1 macro: 0.751777 \n",
      "\n",
      "Saving model to file: resnet34_celeba10attr_10e_2.pt\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.181992  [    0/162770] time: 0.20960307121276855 acc: 0.9156249761581421 precision: 0.8552146553993225 recall: 0.7920228838920593, f1_macro: 0.796072781085968\n",
      "loss: 0.128638  [ 6400/162770] time: 18.56335997581482 acc: 0.9437500238418579 precision: 0.9432913661003113 recall: 0.8429487943649292, f1_macro: 0.8710683584213257\n",
      "loss: 0.119161  [12800/162770] time: 18.48117756843567 acc: 0.9468749761581421 precision: 0.8215124607086182 recall: 0.9519036412239075, f1_macro: 0.8659334182739258\n",
      "loss: 0.150542  [19200/162770] time: 18.436767101287842 acc: 0.9343749284744263 precision: 0.7050395607948303 recall: 0.7192362546920776, f1_macro: 0.7091570496559143\n",
      "loss: 0.141833  [25600/162770] time: 18.603095293045044 acc: 0.932812511920929 precision: 0.7545485496520996 recall: 0.7507678270339966, f1_macro: 0.74793541431427\n",
      "loss: 0.133585  [32000/162770] time: 18.61128520965576 acc: 0.9515624642372131 precision: 0.8596687912940979 recall: 0.8428953289985657, f1_macro: 0.8503744006156921\n",
      "loss: 0.159807  [38400/162770] time: 18.519220113754272 acc: 0.932812511920929 precision: 0.8321726322174072 recall: 0.843969464302063, f1_macro: 0.8354396224021912\n",
      "loss: 0.153826  [44800/162770] time: 18.457464456558228 acc: 0.9312500953674316 precision: 0.888837456703186 recall: 0.8692810535430908, f1_macro: 0.8596745133399963\n",
      "loss: 0.152143  [51200/162770] time: 18.39748454093933 acc: 0.925000011920929 precision: 0.9424209594726562 recall: 0.8480123281478882, f1_macro: 0.8828223943710327\n",
      "loss: 0.120204  [57600/162770] time: 18.43956208229065 acc: 0.949999988079071 precision: 0.8525275588035583 recall: 0.8150817155838013, f1_macro: 0.8317517638206482\n",
      "loss: 0.161697  [64000/162770] time: 18.602975845336914 acc: 0.9390624761581421 precision: 0.8652209043502808 recall: 0.8455223441123962, f1_macro: 0.8532902002334595\n",
      "loss: 0.154800  [70400/162770] time: 18.418376207351685 acc: 0.9390625357627869 precision: 0.9116175770759583 recall: 0.8252390623092651, f1_macro: 0.8356383442878723\n",
      "loss: 0.138485  [76800/162770] time: 18.60730266571045 acc: 0.9359374642372131 precision: 0.8928231000900269 recall: 0.8139030933380127, f1_macro: 0.8299556970596313\n",
      "loss: 0.136810  [83200/162770] time: 18.724858045578003 acc: 0.926562488079071 precision: 0.802573025226593 recall: 0.7798269987106323, f1_macro: 0.7862364053726196\n",
      "loss: 0.153735  [89600/162770] time: 18.564666986465454 acc: 0.934374988079071 precision: 0.8809648752212524 recall: 0.8982456922531128, f1_macro: 0.8869094848632812\n",
      "loss: 0.117694  [96000/162770] time: 18.47663950920105 acc: 0.9468750357627869 precision: 0.936335027217865 recall: 0.8601247668266296, f1_macro: 0.8812589049339294\n",
      "loss: 0.149228  [102400/162770] time: 18.495407819747925 acc: 0.940625011920929 precision: 0.8746016621589661 recall: 0.9317424893379211, f1_macro: 0.8943266868591309\n",
      "loss: 0.155994  [108800/162770] time: 18.51705574989319 acc: 0.9281249046325684 precision: 0.8685386776924133 recall: 0.8455301523208618, f1_macro: 0.8539659976959229\n",
      "loss: 0.130211  [115200/162770] time: 18.60711908340454 acc: 0.932812511920929 precision: 0.8360541462898254 recall: 0.7770327925682068, f1_macro: 0.7910975217819214\n",
      "loss: 0.165015  [121600/162770] time: 18.757909059524536 acc: 0.921875 precision: 0.6890869140625 recall: 0.7430275082588196, f1_macro: 0.7049533128738403\n",
      "loss: 0.141577  [128000/162770] time: 18.59567666053772 acc: 0.9421875476837158 precision: 0.9093203544616699 recall: 0.9085448384284973, f1_macro: 0.9048118591308594\n",
      "loss: 0.154634  [134400/162770] time: 18.75660538673401 acc: 0.9328125715255737 precision: 0.8582145571708679 recall: 0.7676129937171936, f1_macro: 0.8013128042221069\n",
      "loss: 0.148561  [140800/162770] time: 19.02527618408203 acc: 0.9437500238418579 precision: 0.7525790333747864 recall: 0.7200284004211426, f1_macro: 0.7330112457275391\n",
      "loss: 0.127213  [147200/162770] time: 19.012319564819336 acc: 0.940625011920929 precision: 0.8370307683944702 recall: 0.7919523119926453, f1_macro: 0.8086292147636414\n",
      "loss: 0.166902  [153600/162770] time: 18.913144826889038 acc: 0.9249999523162842 precision: 0.8098626732826233 recall: 0.7758989334106445, f1_macro: 0.7855177521705627\n",
      "loss: 0.147727  [160000/162770] time: 19.002423524856567 acc: 0.932812511920929 precision: 0.7159873247146606 recall: 0.7371458411216736, f1_macro: 0.7202730178833008\n",
      "Valid | Error: \n",
      " Accuracy: 0.936017, Precision: 0.833391, Recall: 0.799040, Avg loss: 0.145847, F1 macro: 0.804559 \n",
      "\n",
      "Saving model to file: resnet34_celeba10attr_10e_2.pt\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.138959  [    0/162770] time: 0.19306039810180664 acc: 0.9375000596046448 precision: 0.8287857174873352 recall: 0.747999370098114, f1_macro: 0.7760076522827148\n",
      "loss: 0.106206  [ 6400/162770] time: 18.187296390533447 acc: 0.956250011920929 precision: 0.9081069231033325 recall: 0.9164462685585022, f1_macro: 0.8981385231018066\n",
      "loss: 0.105278  [12800/162770] time: 18.248860836029053 acc: 0.9546874761581421 precision: 0.885179340839386 recall: 0.8270860910415649, f1_macro: 0.8452063798904419\n",
      "loss: 0.148160  [19200/162770] time: 18.04764413833618 acc: 0.934374988079071 precision: 0.9115130305290222 recall: 0.8713986873626709, f1_macro: 0.8821059465408325\n",
      "loss: 0.144343  [25600/162770] time: 18.06064796447754 acc: 0.9328124523162842 precision: 0.8408137559890747 recall: 0.7811254858970642, f1_macro: 0.8054988384246826\n",
      "loss: 0.167559  [32000/162770] time: 18.279930114746094 acc: 0.9234374761581421 precision: 0.7187459468841553 recall: 0.7092918753623962, f1_macro: 0.7117059230804443\n",
      "loss: 0.110968  [38400/162770] time: 18.21971297264099 acc: 0.949999988079071 precision: 0.9360151886940002 recall: 0.8825411200523376, f1_macro: 0.8961023688316345\n",
      "loss: 0.155780  [44800/162770] time: 18.216844081878662 acc: 0.934374988079071 precision: 0.898123025894165 recall: 0.8007339835166931, f1_macro: 0.8203704953193665\n",
      "loss: 0.152981  [51200/162770] time: 18.349586486816406 acc: 0.926562488079071 precision: 0.7202916741371155 recall: 0.7055368423461914, f1_macro: 0.7107869386672974\n",
      "loss: 0.127112  [57600/162770] time: 18.297155380249023 acc: 0.9468750357627869 precision: 0.9065737724304199 recall: 0.9465345144271851, f1_macro: 0.9225237965583801\n",
      "loss: 0.139221  [64000/162770] time: 18.078002452850342 acc: 0.9359375238418579 precision: 0.9003297686576843 recall: 0.9081217050552368, f1_macro: 0.8994361758232117\n",
      "loss: 0.109300  [70400/162770] time: 17.97658348083496 acc: 0.9531249403953552 precision: 0.9322434663772583 recall: 0.8731481432914734, f1_macro: 0.876266598701477\n",
      "loss: 0.142618  [76800/162770] time: 18.131701946258545 acc: 0.9375 precision: 0.8704450130462646 recall: 0.8504209518432617, f1_macro: 0.8298672437667847\n",
      "loss: 0.147358  [83200/162770] time: 18.086514711380005 acc: 0.9359374642372131 precision: 0.810778796672821 recall: 0.8000985980033875, f1_macro: 0.7948482036590576\n",
      "loss: 0.162404  [89600/162770] time: 18.035640001296997 acc: 0.9328124523162842 precision: 0.816228985786438 recall: 0.7526870369911194, f1_macro: 0.7555134892463684\n",
      "loss: 0.113492  [96000/162770] time: 18.071918487548828 acc: 0.9515625834465027 precision: 0.9516708850860596 recall: 0.7995140552520752, f1_macro: 0.8600672483444214\n",
      "loss: 0.124798  [102400/162770] time: 17.887322902679443 acc: 0.942187488079071 precision: 0.8884498476982117 recall: 0.8793711066246033, f1_macro: 0.8826361298561096\n",
      "loss: 0.134697  [108800/162770] time: 18.177614450454712 acc: 0.9468749761581421 precision: 0.9076344966888428 recall: 0.8811274766921997, f1_macro: 0.8810503482818604\n",
      "loss: 0.111585  [115200/162770] time: 18.226967334747314 acc: 0.9546875357627869 precision: 0.9187526702880859 recall: 0.9265902042388916, f1_macro: 0.9153558015823364\n",
      "loss: 0.121598  [121600/162770] time: 18.26862597465515 acc: 0.9390624761581421 precision: 0.8515491485595703 recall: 0.8802111744880676, f1_macro: 0.8396995067596436\n",
      "loss: 0.128791  [128000/162770] time: 18.100330114364624 acc: 0.9484374523162842 precision: 0.7326514720916748 recall: 0.7417902946472168, f1_macro: 0.7365647554397583\n",
      "loss: 0.180008  [134400/162770] time: 18.078486919403076 acc: 0.926562488079071 precision: 0.7635387182235718 recall: 0.787570059299469, f1_macro: 0.7700532674789429\n",
      "loss: 0.127552  [140800/162770] time: 18.31011652946472 acc: 0.9437500238418579 precision: 0.7461875677108765 recall: 0.7308463454246521, f1_macro: 0.7353589534759521\n",
      "loss: 0.141880  [147200/162770] time: 18.191407918930054 acc: 0.940625011920929 precision: 0.9040749669075012 recall: 0.9259989261627197, f1_macro: 0.9037991166114807\n",
      "loss: 0.137122  [153600/162770] time: 18.260847330093384 acc: 0.9468749761581421 precision: 0.8236239552497864 recall: 0.7999358177185059, f1_macro: 0.8043685555458069\n",
      "loss: 0.124992  [160000/162770] time: 18.377381801605225 acc: 0.949999988079071 precision: 0.8287506103515625 recall: 0.7464786767959595, f1_macro: 0.7782742977142334\n",
      "Valid | Error: \n",
      " Accuracy: 0.937408, Precision: 0.826610, Recall: 0.801763, Avg loss: 0.142061, F1 macro: 0.804271 \n",
      "\n",
      "Saving model to file: resnet34_celeba10attr_10e_2.pt\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.125850  [    0/162770] time: 0.1909782886505127 acc: 0.942187488079071 precision: 0.8436225056648254 recall: 0.8245202898979187, f1_macro: 0.8210081458091736\n",
      "loss: 0.123374  [ 6400/162770] time: 18.36672806739807 acc: 0.9406249523162842 precision: 0.8658831715583801 recall: 0.9203681349754333, f1_macro: 0.8743629455566406\n",
      "loss: 0.139261  [12800/162770] time: 18.403021574020386 acc: 0.9421875476837158 precision: 0.7959222197532654 recall: 0.8147903084754944, f1_macro: 0.7797432541847229\n",
      "loss: 0.086936  [19200/162770] time: 18.40077829360962 acc: 0.965624988079071 precision: 0.8849559426307678 recall: 0.7974246144294739, f1_macro: 0.8315168619155884\n",
      "loss: 0.131324  [25600/162770] time: 18.36123275756836 acc: 0.9343750476837158 precision: 0.7815133333206177 recall: 0.7593472599983215, f1_macro: 0.7685297131538391\n",
      "loss: 0.119856  [32000/162770] time: 18.575626611709595 acc: 0.9421875476837158 precision: 0.9007773399353027 recall: 0.9015267491340637, f1_macro: 0.9004416465759277\n",
      "loss: 0.116551  [38400/162770] time: 18.357272148132324 acc: 0.9468749761581421 precision: 0.9383100271224976 recall: 0.8864638805389404, f1_macro: 0.9061684608459473\n",
      "loss: 0.132227  [44800/162770] time: 18.450377464294434 acc: 0.9359374642372131 precision: 0.7666684985160828 recall: 0.7676942348480225, f1_macro: 0.759941577911377\n",
      "loss: 0.142408  [51200/162770] time: 18.368149280548096 acc: 0.9406249523162842 precision: 0.8704466223716736 recall: 0.8735367059707642, f1_macro: 0.8697716593742371\n",
      "loss: 0.121078  [57600/162770] time: 18.46477961540222 acc: 0.9484374523162842 precision: 0.8637837767601013 recall: 0.8662614226341248, f1_macro: 0.8618077039718628\n",
      "loss: 0.124281  [64000/162770] time: 18.394088745117188 acc: 0.9468749761581421 precision: 0.9145009517669678 recall: 0.8970015645027161, f1_macro: 0.9035183787345886\n",
      "loss: 0.110180  [70400/162770] time: 18.59413719177246 acc: 0.942187488079071 precision: 0.9079504609107971 recall: 0.8691709637641907, f1_macro: 0.8844795823097229\n",
      "loss: 0.106680  [76800/162770] time: 18.623058795928955 acc: 0.9437499642372131 precision: 0.8324587941169739 recall: 0.7738775610923767, f1_macro: 0.7850690484046936\n",
      "loss: 0.123826  [83200/162770] time: 18.655235528945923 acc: 0.948437511920929 precision: 0.8599852919578552 recall: 0.8424814343452454, f1_macro: 0.8505232334136963\n",
      "loss: 0.105957  [89600/162770] time: 18.43832015991211 acc: 0.9609375 precision: 0.9259023666381836 recall: 0.8890517354011536, f1_macro: 0.8933324813842773\n",
      "loss: 0.124325  [96000/162770] time: 18.579652547836304 acc: 0.948437511920929 precision: 0.8817863464355469 recall: 0.8864260911941528, f1_macro: 0.8813461661338806\n",
      "loss: 0.134214  [102400/162770] time: 18.559998989105225 acc: 0.9453124403953552 precision: 0.8023629784584045 recall: 0.8116176724433899, f1_macro: 0.8047012090682983\n",
      "loss: 0.110257  [108800/162770] time: 18.41866183280945 acc: 0.953125 precision: 0.831271231174469 recall: 0.7973618507385254, f1_macro: 0.7943516373634338\n",
      "loss: 0.117963  [115200/162770] time: 18.60280418395996 acc: 0.9484375715255737 precision: 0.8282914161682129 recall: 0.8851332664489746, f1_macro: 0.8482022881507874\n",
      "loss: 0.119010  [121600/162770] time: 18.56027841567993 acc: 0.9468749761581421 precision: 0.9121047258377075 recall: 0.8896179795265198, f1_macro: 0.8997350931167603\n",
      "loss: 0.148942  [128000/162770] time: 18.48699402809143 acc: 0.948437511920929 precision: 0.8771127462387085 recall: 0.885646641254425, f1_macro: 0.865394115447998\n",
      "loss: 0.143717  [134400/162770] time: 18.54320502281189 acc: 0.942187488079071 precision: 0.7218641042709351 recall: 0.7428046464920044, f1_macro: 0.7275501489639282\n",
      "loss: 0.117092  [140800/162770] time: 18.424834728240967 acc: 0.9578125476837158 precision: 0.932814359664917 recall: 0.8703535795211792, f1_macro: 0.8833404183387756\n",
      "loss: 0.116158  [147200/162770] time: 18.548097372055054 acc: 0.957812488079071 precision: 0.9254510402679443 recall: 0.9135307669639587, f1_macro: 0.91047203540802\n",
      "loss: 0.141151  [153600/162770] time: 18.56095552444458 acc: 0.9375 precision: 0.8062630891799927 recall: 0.844335675239563, f1_macro: 0.8215581178665161\n",
      "loss: 0.107743  [160000/162770] time: 18.69043231010437 acc: 0.964062511920929 precision: 0.8725427985191345 recall: 0.910724401473999, f1_macro: 0.8829099535942078\n",
      "Valid | Error: \n",
      " Accuracy: 0.926993, Precision: 0.789299, Recall: 0.824876, Avg loss: 0.192270, F1 macro: 0.793517 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.120032  [    0/162770] time: 0.18247389793395996 acc: 0.948437511920929 precision: 0.9065322875976562 recall: 0.8933616876602173, f1_macro: 0.8981812596321106\n",
      "loss: 0.108262  [ 6400/162770] time: 18.463284015655518 acc: 0.956250011920929 precision: 0.9258982539176941 recall: 0.9204644560813904, f1_macro: 0.9227598905563354\n",
      "loss: 0.109359  [12800/162770] time: 18.497097730636597 acc: 0.953125 precision: 0.9129689335823059 recall: 0.8606544733047485, f1_macro: 0.8795911073684692\n",
      "loss: 0.092677  [19200/162770] time: 18.372814178466797 acc: 0.9625000357627869 precision: 0.9630556702613831 recall: 0.8582078218460083, f1_macro: 0.8931897878646851\n",
      "loss: 0.105641  [25600/162770] time: 18.30061435699463 acc: 0.9562500715255737 precision: 0.9038691520690918 recall: 0.9095494747161865, f1_macro: 0.8811888098716736\n",
      "loss: 0.094447  [32000/162770] time: 18.493583917617798 acc: 0.9593750238418579 precision: 0.9067997932434082 recall: 0.9278056621551514, f1_macro: 0.904006838798523\n",
      "loss: 0.097129  [38400/162770] time: 18.567403316497803 acc: 0.9515625238418579 precision: 0.9115060567855835 recall: 0.9414255023002625, f1_macro: 0.9177573919296265\n",
      "loss: 0.135421  [44800/162770] time: 18.434983253479004 acc: 0.9359374642372131 precision: 0.787912905216217 recall: 0.8281026482582092, f1_macro: 0.8003361821174622\n",
      "loss: 0.088746  [51200/162770] time: 18.519441843032837 acc: 0.9749999642372131 precision: 0.9618324041366577 recall: 0.9751833081245422, f1_macro: 0.966955304145813\n",
      "loss: 0.122173  [57600/162770] time: 18.368621349334717 acc: 0.9390624761581421 precision: 0.7758309245109558 recall: 0.7505518198013306, f1_macro: 0.7520325779914856\n",
      "loss: 0.131437  [64000/162770] time: 18.35253405570984 acc: 0.9437500238418579 precision: 0.8547593951225281 recall: 0.8530863523483276, f1_macro: 0.8451711535453796\n",
      "loss: 0.117066  [70400/162770] time: 18.25698232650757 acc: 0.949999988079071 precision: 0.9364269971847534 recall: 0.873320460319519, f1_macro: 0.8812775611877441\n",
      "loss: 0.112781  [76800/162770] time: 18.35478162765503 acc: 0.9500000476837158 precision: 0.8699427843093872 recall: 0.8757913112640381, f1_macro: 0.8679430484771729\n",
      "loss: 0.127793  [83200/162770] time: 18.496289014816284 acc: 0.9546875357627869 precision: 0.9495989084243774 recall: 0.915770411491394, f1_macro: 0.9300482273101807\n",
      "loss: 0.120759  [89600/162770] time: 18.403932571411133 acc: 0.9390625357627869 precision: 0.8530140519142151 recall: 0.9050288796424866, f1_macro: 0.8729122877120972\n",
      "loss: 0.117762  [96000/162770] time: 18.346518993377686 acc: 0.942187488079071 precision: 0.8448145985603333 recall: 0.8343254327774048, f1_macro: 0.836127758026123\n",
      "loss: 0.122630  [102400/162770] time: 18.42852258682251 acc: 0.949999988079071 precision: 0.8926452398300171 recall: 0.9656312465667725, f1_macro: 0.9163472652435303\n",
      "loss: 0.115521  [108800/162770] time: 18.248717546463013 acc: 0.9484374523162842 precision: 0.902087926864624 recall: 0.8804128766059875, f1_macro: 0.8778208494186401\n",
      "loss: 0.111550  [115200/162770] time: 18.22124481201172 acc: 0.9546875953674316 precision: 0.9269948601722717 recall: 0.8425214886665344, f1_macro: 0.8540977835655212\n",
      "loss: 0.094334  [121600/162770] time: 18.29202127456665 acc: 0.9593750238418579 precision: 0.9326916933059692 recall: 0.9551515579223633, f1_macro: 0.9421053528785706\n",
      "loss: 0.109490  [128000/162770] time: 18.695687294006348 acc: 0.9593750238418579 precision: 0.850885272026062 recall: 0.8955601453781128, f1_macro: 0.8643635511398315\n",
      "loss: 0.106121  [134400/162770] time: 18.720160722732544 acc: 0.953125 precision: 0.8025025129318237 recall: 0.8280926942825317, f1_macro: 0.8026401400566101\n",
      "loss: 0.108947  [140800/162770] time: 18.706644535064697 acc: 0.9437500238418579 precision: 0.9416709542274475 recall: 0.8746910691261292, f1_macro: 0.8973106145858765\n",
      "loss: 0.108403  [147200/162770] time: 18.675915956497192 acc: 0.9484375715255737 precision: 0.8693982362747192 recall: 0.9549646377563477, f1_macro: 0.9063096046447754\n",
      "loss: 0.133747  [153600/162770] time: 18.380402088165283 acc: 0.9390625357627869 precision: 0.9014550447463989 recall: 0.9167091846466064, f1_macro: 0.905809760093689\n",
      "loss: 0.117118  [160000/162770] time: 18.24882459640503 acc: 0.949999988079071 precision: 0.7987071871757507 recall: 0.7636566162109375, f1_macro: 0.7787349820137024\n",
      "Valid | Error: \n",
      " Accuracy: 0.932513, Precision: 0.804704, Recall: 0.787982, Avg loss: 0.165108, F1 macro: 0.781519 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.112220  [    0/162770] time: 0.18259096145629883 acc: 0.948437511920929 precision: 0.7400203943252563 recall: 0.7607824802398682, f1_macro: 0.7495192885398865\n",
      "loss: 0.088825  [ 6400/162770] time: 18.187405586242676 acc: 0.9609375596046448 precision: 0.8755552768707275 recall: 0.9245757460594177, f1_macro: 0.8917006850242615\n",
      "loss: 0.076778  [12800/162770] time: 18.29101538658142 acc: 0.9656250476837158 precision: 0.8488226532936096 recall: 0.8232673406600952, f1_macro: 0.8268877863883972\n",
      "loss: 0.100284  [19200/162770] time: 18.264811038970947 acc: 0.9593750834465027 precision: 0.8864935636520386 recall: 0.9387260675430298, f1_macro: 0.8975980281829834\n",
      "loss: 0.082792  [25600/162770] time: 18.482097864151 acc: 0.9624999761581421 precision: 0.9353623390197754 recall: 0.9693247675895691, f1_macro: 0.9499613642692566\n",
      "loss: 0.123537  [32000/162770] time: 18.1782124042511 acc: 0.9515625834465027 precision: 0.8906621932983398 recall: 0.9483827948570251, f1_macro: 0.9154459238052368\n",
      "loss: 0.107179  [38400/162770] time: 18.258143424987793 acc: 0.9500000476837158 precision: 0.9806287288665771 recall: 0.871151864528656, f1_macro: 0.9130100011825562\n",
      "loss: 0.075689  [44800/162770] time: 18.2054545879364 acc: 0.9671875834465027 precision: 0.8676915168762207 recall: 0.8567416071891785, f1_macro: 0.8613894581794739\n",
      "loss: 0.091575  [51200/162770] time: 18.119755029678345 acc: 0.953125 precision: 0.9254611730575562 recall: 0.9383018016815186, f1_macro: 0.929656982421875\n",
      "loss: 0.095581  [57600/162770] time: 18.25467300415039 acc: 0.9546874761581421 precision: 0.8190091848373413 recall: 0.8097083568572998, f1_macro: 0.8113102316856384\n",
      "loss: 0.138509  [64000/162770] time: 18.44254207611084 acc: 0.9421874284744263 precision: 0.9256415963172913 recall: 0.8577408194541931, f1_macro: 0.8756184577941895\n",
      "loss: 0.112000  [70400/162770] time: 18.303465843200684 acc: 0.9484375715255737 precision: 0.9674385786056519 recall: 0.8431371450424194, f1_macro: 0.8889429569244385\n",
      "loss: 0.104506  [76800/162770] time: 18.112656354904175 acc: 0.9624999761581421 precision: 0.8750004768371582 recall: 0.8103146553039551, f1_macro: 0.8332474231719971\n",
      "loss: 0.086108  [83200/162770] time: 18.392845392227173 acc: 0.96875 precision: 0.9494165778160095 recall: 0.9311882853507996, f1_macro: 0.9288842678070068\n",
      "loss: 0.090446  [89600/162770] time: 18.33490800857544 acc: 0.9546875357627869 precision: 0.9129748344421387 recall: 0.9167952537536621, f1_macro: 0.9096048474311829\n",
      "loss: 0.113422  [96000/162770] time: 18.437647104263306 acc: 0.9500000476837158 precision: 0.9697501063346863 recall: 0.8918823003768921, f1_macro: 0.9254679679870605\n",
      "loss: 0.083420  [102400/162770] time: 18.542100191116333 acc: 0.9609374403953552 precision: 0.8036805391311646 recall: 0.8106786012649536, f1_macro: 0.8063583374023438\n",
      "loss: 0.062831  [108800/162770] time: 18.659066915512085 acc: 0.9718749523162842 precision: 0.9533413052558899 recall: 0.9543907046318054, f1_macro: 0.9513819813728333\n",
      "loss: 0.114039  [115200/162770] time: 18.70077919960022 acc: 0.953125 precision: 0.9488227963447571 recall: 0.9185516238212585, f1_macro: 0.9298155307769775\n",
      "loss: 0.090281  [121600/162770] time: 18.63719940185547 acc: 0.9671875238418579 precision: 0.8429985046386719 recall: 0.8697044849395752, f1_macro: 0.8548902273178101\n",
      "loss: 0.102273  [128000/162770] time: 18.55603575706482 acc: 0.956250011920929 precision: 0.9200423955917358 recall: 0.9575867652893066, f1_macro: 0.9352648854255676\n",
      "loss: 0.085392  [134400/162770] time: 18.548685789108276 acc: 0.9703125357627869 precision: 0.8810532093048096 recall: 0.8299242854118347, f1_macro: 0.8513578772544861\n",
      "loss: 0.119506  [140800/162770] time: 18.471785306930542 acc: 0.9562500715255737 precision: 0.9474235773086548 recall: 0.8694095611572266, f1_macro: 0.8943299055099487\n",
      "loss: 0.090635  [147200/162770] time: 18.37673306465149 acc: 0.9625000357627869 precision: 0.7592864632606506 recall: 0.7403052449226379, f1_macro: 0.7490692734718323\n",
      "loss: 0.097724  [153600/162770] time: 18.5824294090271 acc: 0.9499999284744263 precision: 0.8891090154647827 recall: 0.944482147693634, f1_macro: 0.9124068021774292\n",
      "loss: 0.084994  [160000/162770] time: 18.561426401138306 acc: 0.9625000357627869 precision: 0.9547916650772095 recall: 0.9039723873138428, f1_macro: 0.9193600416183472\n",
      "Valid | Error: \n",
      " Accuracy: 0.929202, Precision: 0.832900, Recall: 0.790715, Avg loss: 0.170617, F1 macro: 0.799191 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.091426  [    0/162770] time: 0.1854550838470459 acc: 0.9624999761581421 precision: 0.9746377468109131 recall: 0.8671166896820068, f1_macro: 0.907235860824585\n",
      "loss: 0.049290  [ 6400/162770] time: 18.41901707649231 acc: 0.9859375357627869 precision: 0.9368736147880554 recall: 0.9197903275489807, f1_macro: 0.9031161069869995\n",
      "loss: 0.087689  [12800/162770] time: 18.561784267425537 acc: 0.9624999761581421 precision: 0.9038940668106079 recall: 0.9065442085266113, f1_macro: 0.8888038396835327\n",
      "loss: 0.039688  [19200/162770] time: 18.418378591537476 acc: 0.984375 precision: 0.8914391994476318 recall: 0.8736759424209595, f1_macro: 0.8820247054100037\n",
      "loss: 0.091320  [25600/162770] time: 18.380491018295288 acc: 0.964062511920929 precision: 0.9550585746765137 recall: 0.9267926812171936, f1_macro: 0.9395121335983276\n",
      "loss: 0.086392  [32000/162770] time: 18.3023681640625 acc: 0.9640624523162842 precision: 0.7768170833587646 recall: 0.7278256416320801, f1_macro: 0.7473437190055847\n",
      "loss: 0.097841  [38400/162770] time: 18.200595378875732 acc: 0.957812488079071 precision: 0.810206413269043 recall: 0.8410037755966187, f1_macro: 0.8241270184516907\n",
      "loss: 0.052140  [44800/162770] time: 18.4415545463562 acc: 0.981249988079071 precision: 0.7786107659339905 recall: 0.7753174901008606, f1_macro: 0.7761831283569336\n",
      "loss: 0.054945  [51200/162770] time: 18.296382188796997 acc: 0.971875011920929 precision: 0.884444534778595 recall: 0.8579643964767456, f1_macro: 0.8700419664382935\n",
      "loss: 0.078009  [57600/162770] time: 18.339200496673584 acc: 0.96875 precision: 0.8732201457023621 recall: 0.8490511775016785, f1_macro: 0.8589279651641846\n",
      "loss: 0.066561  [64000/162770] time: 18.448817014694214 acc: 0.9765625 precision: 0.8292514085769653 recall: 0.8124580979347229, f1_macro: 0.8183825612068176\n",
      "loss: 0.057835  [70400/162770] time: 18.485284328460693 acc: 0.979687511920929 precision: 0.8612924814224243 recall: 0.8683090209960938, f1_macro: 0.8636811971664429\n",
      "loss: 0.078946  [76800/162770] time: 18.623178005218506 acc: 0.9671875834465027 precision: 0.948954164981842 recall: 0.9672099351882935, f1_macro: 0.9565614461898804\n",
      "loss: 0.089495  [83200/162770] time: 18.534822463989258 acc: 0.956250011920929 precision: 0.8484746217727661 recall: 0.8530246019363403, f1_macro: 0.8470094799995422\n",
      "loss: 0.093810  [89600/162770] time: 18.58487582206726 acc: 0.9546875357627869 precision: 0.8263108134269714 recall: 0.8752694129943848, f1_macro: 0.848448634147644\n",
      "loss: 0.080492  [96000/162770] time: 18.39372730255127 acc: 0.9656250476837158 precision: 0.9540396928787231 recall: 0.9500112533569336, f1_macro: 0.9485029578208923\n",
      "loss: 0.101050  [102400/162770] time: 18.45717191696167 acc: 0.9578124284744263 precision: 0.8537881970405579 recall: 0.7888575792312622, f1_macro: 0.8121380805969238\n",
      "loss: 0.084134  [108800/162770] time: 18.366076231002808 acc: 0.9718750715255737 precision: 0.9631244540214539 recall: 0.941891074180603, f1_macro: 0.9485198259353638\n",
      "loss: 0.059972  [115200/162770] time: 18.578466415405273 acc: 0.9734375476837158 precision: 0.936772882938385 recall: 0.97148197889328, f1_macro: 0.952087938785553\n",
      "loss: 0.058991  [121600/162770] time: 18.679297924041748 acc: 0.9781249761581421 precision: 0.979541003704071 recall: 0.9694666266441345, f1_macro: 0.9742904901504517\n",
      "loss: 0.086335  [128000/162770] time: 18.505960702896118 acc: 0.9671874642372131 precision: 0.8608367443084717 recall: 0.8509389758110046, f1_macro: 0.8546386957168579\n",
      "loss: 0.064273  [134400/162770] time: 18.506646394729614 acc: 0.9750000834465027 precision: 0.9607442021369934 recall: 0.9584017992019653, f1_macro: 0.9569920897483826\n",
      "loss: 0.080578  [140800/162770] time: 18.9008150100708 acc: 0.9609375 precision: 0.9386250376701355 recall: 0.9127252697944641, f1_macro: 0.9155600070953369\n",
      "loss: 0.070169  [147200/162770] time: 18.772732734680176 acc: 0.9718750715255737 precision: 0.8803081512451172 recall: 0.8350685834884644, f1_macro: 0.855216383934021\n",
      "loss: 0.068797  [153600/162770] time: 18.689915895462036 acc: 0.9703125357627869 precision: 0.9301283359527588 recall: 0.9598236680030823, f1_macro: 0.9386606216430664\n",
      "loss: 0.093546  [160000/162770] time: 18.829656839370728 acc: 0.9593750238418579 precision: 0.9194502830505371 recall: 0.8850284814834595, f1_macro: 0.8883949518203735\n",
      "Valid | Error: \n",
      " Accuracy: 0.933140, Precision: 0.834316, Recall: 0.820841, Avg loss: 0.185554, F1 macro: 0.817301 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.068735  [    0/162770] time: 0.19265341758728027 acc: 0.9734374284744263 precision: 0.9046140909194946 recall: 0.9678042531013489, f1_macro: 0.9264039397239685\n",
      "loss: 0.037402  [ 6400/162770] time: 18.560762405395508 acc: 0.9828125238418579 precision: 0.9782251715660095 recall: 0.9314935207366943, f1_macro: 0.9495640397071838\n",
      "loss: 0.047465  [12800/162770] time: 18.514736890792847 acc: 0.979687511920929 precision: 0.9716616868972778 recall: 0.9115934371948242, f1_macro: 0.9188889861106873\n",
      "loss: 0.053964  [19200/162770] time: 18.5073881149292 acc: 0.984375 precision: 0.8871827125549316 recall: 0.8685575127601624, f1_macro: 0.8775591850280762\n",
      "loss: 0.047395  [25600/162770] time: 18.44302797317505 acc: 0.9812500476837158 precision: 0.9845490455627441 recall: 0.9760058522224426, f1_macro: 0.9799982905387878\n",
      "loss: 0.083971  [32000/162770] time: 18.748850345611572 acc: 0.964062511920929 precision: 0.8450104594230652 recall: 0.807386577129364, f1_macro: 0.8153210282325745\n",
      "loss: 0.063285  [38400/162770] time: 18.679892778396606 acc: 0.9750000238418579 precision: 0.9196643829345703 recall: 0.9808896780014038, f1_macro: 0.9437507390975952\n",
      "loss: 0.058169  [44800/162770] time: 18.80374526977539 acc: 0.9750000238418579 precision: 0.9635714888572693 recall: 0.9141991138458252, f1_macro: 0.9292901754379272\n",
      "loss: 0.052741  [51200/162770] time: 18.87524151802063 acc: 0.979687511920929 precision: 0.9714498519897461 recall: 0.9805142879486084, f1_macro: 0.9756755232810974\n",
      "loss: 0.057567  [57600/162770] time: 18.797876119613647 acc: 0.9781249761581421 precision: 0.921340823173523 recall: 0.9331304430961609, f1_macro: 0.9264692068099976\n",
      "loss: 0.058667  [64000/162770] time: 18.604609489440918 acc: 0.9718749523162842 precision: 0.945387601852417 recall: 0.9512245655059814, f1_macro: 0.944128692150116\n",
      "loss: 0.072024  [70400/162770] time: 18.49387550354004 acc: 0.9656250476837158 precision: 0.9137400984764099 recall: 0.9425986409187317, f1_macro: 0.9217047095298767\n",
      "loss: 0.066862  [76800/162770] time: 18.723506689071655 acc: 0.973437488079071 precision: 0.974923849105835 recall: 0.9503571391105652, f1_macro: 0.9613826274871826\n",
      "loss: 0.063357  [83200/162770] time: 18.782517433166504 acc: 0.9812500476837158 precision: 0.9841468930244446 recall: 0.9636144042015076, f1_macro: 0.9716048240661621\n",
      "loss: 0.065752  [89600/162770] time: 18.832019090652466 acc: 0.9656250476837158 precision: 0.8554558157920837 recall: 0.8667348623275757, f1_macro: 0.8599458336830139\n",
      "loss: 0.095939  [96000/162770] time: 18.892742395401 acc: 0.956250011920929 precision: 0.890607476234436 recall: 0.8872386813163757, f1_macro: 0.888203501701355\n",
      "loss: 0.055047  [102400/162770] time: 18.940073490142822 acc: 0.9750000238418579 precision: 0.962611973285675 recall: 0.9533455967903137, f1_macro: 0.9543233513832092\n",
      "loss: 0.053028  [108800/162770] time: 18.798665046691895 acc: 0.9750000238418579 precision: 0.8423953652381897 recall: 0.8660558462142944, f1_macro: 0.8452962636947632\n",
      "loss: 0.068551  [115200/162770] time: 18.773382902145386 acc: 0.9703125357627869 precision: 0.9390060901641846 recall: 0.9368683099746704, f1_macro: 0.9307054281234741\n",
      "loss: 0.078049  [121600/162770] time: 18.86841893196106 acc: 0.9687500596046448 precision: 0.9337347149848938 recall: 0.9400852918624878, f1_macro: 0.9256510734558105\n",
      "loss: 0.077326  [128000/162770] time: 18.74099373817444 acc: 0.9671874642372131 precision: 0.9262281656265259 recall: 0.9014518857002258, f1_macro: 0.913190484046936\n",
      "loss: 0.077663  [134400/162770] time: 18.567070245742798 acc: 0.9640625715255737 precision: 0.891265332698822 recall: 0.9777525067329407, f1_macro: 0.928087055683136\n",
      "loss: 0.055587  [140800/162770] time: 18.644296646118164 acc: 0.9749999642372131 precision: 0.7701682448387146 recall: 0.7678104043006897, f1_macro: 0.7686136364936829\n",
      "loss: 0.089216  [147200/162770] time: 18.718060731887817 acc: 0.9624999761581421 precision: 0.798002302646637 recall: 0.8107797503471375, f1_macro: 0.8015599846839905\n",
      "loss: 0.063454  [153600/162770] time: 18.71907615661621 acc: 0.9749999642372131 precision: 0.9231022000312805 recall: 0.9602388143539429, f1_macro: 0.9382155537605286\n",
      "loss: 0.062214  [160000/162770] time: 18.8914897441864 acc: 0.9750000834465027 precision: 0.8718045949935913 recall: 0.8094326853752136, f1_macro: 0.82375568151474\n",
      "Valid | Error: \n",
      " Accuracy: 0.932100, Precision: 0.817739, Recall: 0.819771, Avg loss: 0.204751, F1 macro: 0.808900 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.041433  [    0/162770] time: 0.18776202201843262 acc: 0.9859375357627869 precision: 0.89000004529953 recall: 0.8826751708984375, f1_macro: 0.8857905268669128\n",
      "loss: 0.029879  [ 6400/162770] time: 18.617663621902466 acc: 0.9921875 precision: 0.8732278943061829 recall: 0.8966667652130127, f1_macro: 0.8844194412231445\n",
      "loss: 0.038419  [12800/162770] time: 18.87293243408203 acc: 0.9859375953674316 precision: 0.8931035399436951 recall: 0.9318692088127136, f1_macro: 0.9037668108940125\n",
      "loss: 0.022160  [19200/162770] time: 18.81861400604248 acc: 0.9937500953674316 precision: 0.9842742085456848 recall: 0.9947369694709778, f1_macro: 0.988991379737854\n",
      "loss: 0.033034  [25600/162770] time: 18.774264335632324 acc: 0.9875000715255737 precision: 0.9844756126403809 recall: 0.9859637022018433, f1_macro: 0.9849153161048889\n",
      "loss: 0.036626  [32000/162770] time: 18.611201286315918 acc: 0.979687511920929 precision: 0.9669281244277954 recall: 0.9446118474006653, f1_macro: 0.9545210599899292\n",
      "loss: 0.040249  [38400/162770] time: 18.64262843132019 acc: 0.9812500476837158 precision: 0.9802614450454712 recall: 0.9766035079956055, f1_macro: 0.9775251150131226\n",
      "loss: 0.044893  [44800/162770] time: 18.579973459243774 acc: 0.9828125834465027 precision: 0.9789683222770691 recall: 0.9845372438430786, f1_macro: 0.9814586043357849\n",
      "loss: 0.028548  [51200/162770] time: 18.598268270492554 acc: 0.9921875596046448 precision: 0.9683334231376648 recall: 0.9875000715255737, f1_macro: 0.9755993485450745\n",
      "loss: 0.051734  [57600/162770] time: 18.901455640792847 acc: 0.9781249761581421 precision: 0.8615629076957703 recall: 0.8839743733406067, f1_macro: 0.872439444065094\n",
      "loss: 0.035199  [64000/162770] time: 18.668625831604004 acc: 0.9859375357627869 precision: 0.9736559391021729 recall: 0.9760517477989197, f1_macro: 0.9734091758728027\n",
      "loss: 0.054227  [70400/162770] time: 18.805639266967773 acc: 0.9828125238418579 precision: 0.9711790084838867 recall: 0.9814815521240234, f1_macro: 0.9749110341072083\n",
      "loss: 0.053988  [76800/162770] time: 18.667035579681396 acc: 0.9859375357627869 precision: 0.986968457698822 recall: 0.9740408658981323, f1_macro: 0.9801880121231079\n",
      "loss: 0.047058  [83200/162770] time: 18.83834481239319 acc: 0.9812500476837158 precision: 0.9818797707557678 recall: 0.9555253386497498, f1_macro: 0.9681556224822998\n",
      "loss: 0.052388  [89600/162770] time: 18.74576997756958 acc: 0.9781250357627869 precision: 0.9780431985855103 recall: 0.9531331062316895, f1_macro: 0.9627070426940918\n",
      "loss: 0.030196  [96000/162770] time: 18.739063024520874 acc: 0.9843750596046448 precision: 1.0000001192092896 recall: 0.877083420753479, f1_macro: 0.9210166931152344\n",
      "loss: 0.044008  [102400/162770] time: 18.700730085372925 acc: 0.9812500476837158 precision: 0.861014723777771 recall: 0.888888955116272, f1_macro: 0.8742014169692993\n",
      "loss: 0.038636  [108800/162770] time: 18.858376264572144 acc: 0.989062488079071 precision: 0.8860041499137878 recall: 0.89000004529953, f1_macro: 0.887591540813446\n",
      "loss: 0.035153  [115200/162770] time: 18.862942695617676 acc: 0.9812500476837158 precision: 0.9853782653808594 recall: 0.9649569988250732, f1_macro: 0.9747475385665894\n",
      "loss: 0.048557  [121600/162770] time: 18.916733026504517 acc: 0.9828125238418579 precision: 0.9794406890869141 recall: 0.9089285731315613, f1_macro: 0.9338414669036865\n",
      "loss: 0.046092  [128000/162770] time: 18.879364252090454 acc: 0.984375 precision: 0.8743943572044373 recall: 0.8859999775886536, f1_macro: 0.8793970346450806\n",
      "loss: 0.039057  [134400/162770] time: 18.82942843437195 acc: 0.9875000715255737 precision: 0.8949882984161377 recall: 0.8453598618507385, f1_macro: 0.8659226298332214\n",
      "loss: 0.061231  [140800/162770] time: 18.86559557914734 acc: 0.973437488079071 precision: 0.9373290538787842 recall: 0.9593694806098938, f1_macro: 0.9451556205749512\n",
      "loss: 0.052138  [147200/162770] time: 19.073437929153442 acc: 0.9749999642372131 precision: 0.9882354140281677 recall: 0.9183877110481262, f1_macro: 0.9495583176612854\n",
      "loss: 0.042517  [153600/162770] time: 18.842664003372192 acc: 0.981249988079071 precision: 0.9045772552490234 recall: 0.988764226436615, f1_macro: 0.9358367323875427\n",
      "loss: 0.047945  [160000/162770] time: 18.84439706802368 acc: 0.9812500476837158 precision: 0.8831913471221924 recall: 0.8242959380149841, f1_macro: 0.8452953696250916\n",
      "Valid | Error: \n",
      " Accuracy: 0.931325, Precision: 0.820437, Recall: 0.800995, Avg loss: 0.234298, F1 macro: 0.802099 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.040668  [    0/162770] time: 0.18146848678588867 acc: 0.9859375357627869 precision: 0.881442666053772 recall: 0.8865540027618408, f1_macro: 0.8835288882255554\n",
      "loss: 0.015995  [ 6400/162770] time: 18.33054494857788 acc: 0.9984375834465027 precision: 0.9000000953674316 recall: 0.8979592323303223, f1_macro: 0.8989691734313965\n",
      "loss: 0.025135  [12800/162770] time: 18.67936897277832 acc: 0.9890625476837158 precision: 0.9789744019508362 recall: 0.9462963938713074, f1_macro: 0.9538947939872742\n",
      "loss: 0.043968  [19200/162770] time: 18.75120711326599 acc: 0.9859375357627869 precision: 0.9932381510734558 recall: 0.9774356484413147, f1_macro: 0.9850041270256042\n",
      "loss: 0.030033  [25600/162770] time: 18.65776538848877 acc: 0.9875000715255737 precision: 0.9826535582542419 recall: 0.9880404472351074, f1_macro: 0.9852003455162048\n",
      "loss: 0.042664  [32000/162770] time: 18.68716526031494 acc: 0.9859375953674316 precision: 0.9767128825187683 recall: 0.9889295697212219, f1_macro: 0.9824016094207764\n",
      "loss: 0.035025  [38400/162770] time: 18.69614028930664 acc: 0.9859375953674316 precision: 0.971551775932312 recall: 0.9832157492637634, f1_macro: 0.976276695728302\n",
      "loss: 0.027549  [44800/162770] time: 18.669278860092163 acc: 0.9906250238418579 precision: 0.8760476112365723 recall: 0.8800000548362732, f1_macro: 0.8760077953338623\n",
      "loss: 0.029108  [51200/162770] time: 18.62133002281189 acc: 0.987500011920929 precision: 0.9951021075248718 recall: 0.9359524250030518, f1_macro: 0.9602929353713989\n",
      "loss: 0.029385  [57600/162770] time: 18.622621774673462 acc: 0.9890625476837158 precision: 0.894230842590332 recall: 0.8831071853637695, f1_macro: 0.8881481289863586\n",
      "loss: 0.033437  [64000/162770] time: 18.417481184005737 acc: 0.987500011920929 precision: 0.9439559578895569 recall: 0.9930289387702942, f1_macro: 0.9641069173812866\n",
      "loss: 0.055423  [70400/162770] time: 18.704182624816895 acc: 0.9828125238418579 precision: 0.9727316498756409 recall: 0.9779775142669678, f1_macro: 0.974165678024292\n",
      "loss: 0.031667  [76800/162770] time: 18.73251223564148 acc: 0.9859375357627869 precision: 0.9820212125778198 recall: 0.9849265217781067, f1_macro: 0.9834011793136597\n",
      "loss: 0.036510  [83200/162770] time: 18.82369065284729 acc: 0.9859375357627869 precision: 0.8953365683555603 recall: 0.8699632287025452, f1_macro: 0.8820105791091919\n",
      "loss: 0.024744  [89600/162770] time: 18.80716061592102 acc: 0.9890625476837158 precision: 0.9776785969734192 recall: 0.9561988115310669, f1_macro: 0.9627136588096619\n",
      "loss: 0.021309  [96000/162770] time: 18.802212476730347 acc: 0.9906250834465027 precision: 0.992854118347168 recall: 0.9888889789581299, f1_macro: 0.9906661510467529\n",
      "loss: 0.038064  [102400/162770] time: 18.721604824066162 acc: 0.9828125238418579 precision: 0.9798876643180847 recall: 0.9149289131164551, f1_macro: 0.9299062490463257\n",
      "loss: 0.041911  [108800/162770] time: 18.761977434158325 acc: 0.9828125238418579 precision: 0.935763955116272 recall: 0.9768908023834229, f1_macro: 0.9501180648803711\n",
      "loss: 0.021877  [115200/162770] time: 18.59056520462036 acc: 0.9937500953674316 precision: 1.0000001192092896 recall: 0.9900179505348206, f1_macro: 0.9949226379394531\n",
      "loss: 0.044355  [121600/162770] time: 18.61555814743042 acc: 0.979687511920929 precision: 0.9577651023864746 recall: 0.9408334493637085, f1_macro: 0.9398453235626221\n",
      "loss: 0.027713  [128000/162770] time: 18.74654984474182 acc: 0.9937500953674316 precision: 0.9826546907424927 recall: 0.998181939125061, f1_macro: 0.9897592067718506\n",
      "loss: 0.037738  [134400/162770] time: 18.52738904953003 acc: 0.9843750596046448 precision: 0.773906946182251 recall: 0.7916541695594788, f1_macro: 0.7824841141700745\n",
      "loss: 0.038151  [140800/162770] time: 18.634006023406982 acc: 0.989062488079071 precision: 0.9903469681739807 recall: 0.9736695289611816, f1_macro: 0.9805467128753662\n",
      "loss: 0.040548  [147200/162770] time: 18.673118352890015 acc: 0.9921875596046448 precision: 0.9000000953674316 recall: 0.8910983204841614, f1_macro: 0.8954757452011108\n",
      "loss: 0.036162  [153600/162770] time: 18.415364503860474 acc: 0.9859375357627869 precision: 0.8650635480880737 recall: 0.8849003314971924, f1_macro: 0.873399019241333\n",
      "loss: 0.035116  [160000/162770] time: 18.647077560424805 acc: 0.9890626072883606 precision: 0.9478724002838135 recall: 0.9809174537658691, f1_macro: 0.9557160139083862\n",
      "Valid | Error: \n",
      " Accuracy: 0.926075, Precision: 0.801432, Recall: 0.833753, Avg loss: 0.331576, F1 macro: 0.804964 \n",
      "\n",
      "Done!\n",
      "Test | Error: \n",
      " Accuracy: 0.937564, Precision: 0.829868, Recall: 0.808677, Avg loss: 0.146304, F1 macro: 0.808912 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models.MultilabelResnetClassifier import MultilabelResnetClassifier\n",
    "from pytorch_nn import NNUtil\n",
    "\n",
    "model = MultilabelResnetClassifier(n_classes=len(features))\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "save_filename = 'resnet34_celeba10attr_10e_2.pt'\n",
    "\n",
    "experiment = Experiment(\n",
    "api_key = 'MqskAFE0NPXT89J9t3bXaz6ac',\n",
    "project_name = 'pytorch-resnet34-classifier',\n",
    "workspace='wicwik',\n",
    "log_code=True\n",
    ")\n",
    "\n",
    "hyper_params = {\n",
    "'learning_rate': learning_rate,\n",
    "'batch_size': batch_size,\n",
    "'steps': len(train_dataloader)//batch_size,\n",
    "'loss': 'BCELoss',\n",
    "'optimizer': \"Adam\",\n",
    "'save_filename': save_filename\n",
    "}\n",
    "\n",
    "experiment.set_name('resnet_drop02_fc10_2')\n",
    "experiment.log_parameters(hyper_params)\n",
    "\n",
    "log_model(experiment, model, model_name='MultilabelResnet34-CelebA-10attributes')\n",
    "experiment.set_model_graph(model, overwrite=False)\n",
    "\n",
    "dataloaders={'train': train_dataloader, 'valid': valid_dataloader, 'test': test_dataloader}\n",
    "trainer = NNUtil(model=model, dataloaders=dataloaders, loss_fn=loss_fn, optimizer=optimizer, save_filename=save_filename, experiment=experiment)\n",
    "\n",
    "trainer.run_classifier_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14cd6152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/wicwik/pytorch-resnet34-classifier/af5d78196ae74640b10b8b6e0e9df240\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     avg_test_accuracy_per_epoch        : 0.9375636577606201\n",
      "COMET INFO:     avg_test_f1_macro_per_epoch        : 0.8089115619659424\n",
      "COMET INFO:     avg_test_loss_per_epoch            : 0.14630392611695406\n",
      "COMET INFO:     avg_test_precision_per_epoch       : 0.8298677206039429\n",
      "COMET INFO:     avg_test_recall_per_epoch          : 0.8086774349212646\n",
      "COMET INFO:     avg_train_accuracy_per_epoch [10]  : (0.9281567931175232, 0.9859073758125305)\n",
      "COMET INFO:     avg_train_f1_macro_per_epoch [10]  : (0.7856461405754089, 0.93782639503479)\n",
      "COMET INFO:     avg_train_loss_per_epoch [10]      : (0.0366861970953163, 0.16646752762461794)\n",
      "COMET INFO:     avg_train_precision_per_epoch [10] : (0.8065904378890991, 0.939708948135376)\n",
      "COMET INFO:     avg_train_recall_per_epoch [10]    : (0.7875319719314575, 0.941129207611084)\n",
      "COMET INFO:     avg_valid_accuracy_per_epoch [10]  : (0.9164001941680908, 0.9374076724052429)\n",
      "COMET INFO:     avg_valid_f1_macro_per_epoch [10]  : (0.7517773509025574, 0.8173010945320129)\n",
      "COMET INFO:     avg_valid_loss_per_epoch [10]      : (0.14206131348847575, 0.33157610380572905)\n",
      "COMET INFO:     avg_valid_precision_per_epoch [10] : (0.7616812586784363, 0.8343157768249512)\n",
      "COMET INFO:     avg_valid_recall_per_epoch [10]    : (0.778060793876648, 0.8337525725364685)\n",
      "COMET INFO:     train_accuracy [25440]             : (0.37187498807907104, 1.0000001192092896)\n",
      "COMET INFO:     train_f1_macro [25440]             : (0.3440707325935364, 1.0000001192092896)\n",
      "COMET INFO:     train_loss [25440]                 : (0.008825406432151794, 0.844471275806427)\n",
      "COMET INFO:     train_precision [25440]            : (0.34300729632377625, 1.0000001192092896)\n",
      "COMET INFO:     train_recall [25440]               : (0.4698459506034851, 1.0000001192092896)\n",
      "COMET INFO:     valid_accuracy [3422]              : (0.8828125, 0.965624988079071)\n",
      "COMET INFO:     valid_f1_macro [3422]              : (0.47852545976638794, 0.9422391653060913)\n",
      "COMET INFO:     valid_loss [3422]                  : (0.09744268655776978, 0.6648061871528625)\n",
      "COMET INFO:     valid_precision [3422]             : (0.48387444019317627, 0.9636550545692444)\n",
      "COMET INFO:     valid_recall [3422]                : (0.4765656590461731, 0.9803680181503296)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Name : resnet_drop02_fc10_2\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     batch_size    : 64\n",
      "COMET INFO:     learning_rate : 0.001\n",
      "COMET INFO:     loss          : BCELoss\n",
      "COMET INFO:     optimizer     : Adam\n",
      "COMET INFO:     save_filename : resnet34_celeba10attr_10e_2.pt\n",
      "COMET INFO:     steps         : 39\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     conda-environment-definition : 1\n",
      "COMET INFO:     conda-info                   : 1\n",
      "COMET INFO:     conda-specification          : 1\n",
      "COMET INFO:     environment details          : 1\n",
      "COMET INFO:     filename                     : 1\n",
      "COMET INFO:     git metadata                 : 1\n",
      "COMET INFO:     git-patch (uncompressed)     : 1 (120.09 KB)\n",
      "COMET INFO:     installed packages           : 1\n",
      "COMET INFO:     model graph                  : 1\n",
      "COMET INFO:     model-element                : 2 (81.35 MB)\n",
      "COMET INFO:     notebook                     : 1\n",
      "COMET INFO:     source_code                  : 1\n",
      "COMET INFO: \n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish uploading collected data\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
